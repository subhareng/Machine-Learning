{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparseregression (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"SparseRegression.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function evaluate(X,y,β)\n",
    "    norm(y - X * β)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lasso_reg (generic function with 1 method)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function lasso_reg(X, y, ρ)\n",
    "    m = Model(solver=GurobiSolver(OutputFlag=0))\n",
    "\n",
    "    p = size(X, 2)\n",
    "\n",
    "    # Variables\n",
    "    @variable(m, t)\n",
    "    @variable(m, θ)\n",
    "    @variable(m, β[1:p])\n",
    "    @variable(m, z[1:p])\n",
    "\n",
    "    # Constraints\n",
    "    @constraint(m, norm(y - X * β) <= t)\n",
    "    @constraint(m, sum(z[j] for j = 1:p) <= θ)\n",
    "    @constraint(m, [j=1:p], z[j] >=  β[j])\n",
    "    @constraint(m, [j=1:p], z[j] >= -β[j])\n",
    "\n",
    "    # Objective\n",
    "    @objective(m, Min, t + ρ * θ)\n",
    "\n",
    "    solve(m)\n",
    "\n",
    "    return getvalue(β)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "detection_rate (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function detection_rate(pred, truth)\n",
    "    k = countnz(truth)\n",
    "    inds_true = find(truth)\n",
    "    inds_pred = find(pred)\n",
    "    A = length(intersect(inds_true, inds_pred)) / k\n",
    "    F = length(setdiff(inds_pred, inds_true)) / length(inds_pred)\n",
    "    return A, F\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparseregressionbigM (generic function with 1 method)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using JuMP, Gurobi\n",
    "\n",
    "function sparseregressionbigM(X, y, k, M)\n",
    "    m = Model(solver=GurobiSolver(OutputFlag=0, TimeLimit = 1500))\n",
    "    \n",
    "    p = size(X, 2)\n",
    "\n",
    "    # Variables\n",
    "    @variable(m, t)\n",
    "    @variable(m, β[1:p])\n",
    "    @variable(m, s[1:p], Bin)\n",
    "\n",
    "    # Constraints\n",
    "    @constraint(m, norm(y - X * β) <= t)\n",
    "    @constraint(m, sum(s[j] for j = 1:p) <= k)\n",
    "    @constraint(m, [j=1:p], β[j] <=  M * s[j])\n",
    "    @constraint(m, [j=1:p], β[j] >= -M * s[j])\n",
    "\n",
    "    # Objective\n",
    "    @objective(m, Min, t)\n",
    "\n",
    "    solve(m)\n",
    "\n",
    "    return getvalue(β), getobjectivevalue(m)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using MLDataUtils\n",
    "using DataFrames\n",
    "using DataFramesMeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "myDataX = readtable(\"C:/Users/subha/Desktop/ML - HW 2/sparseX2.csv\",header=false);\n",
    "myDataY = readtable(\"C:/Users/subha/Desktop/ML - HW 2/sparseY2.csv\",header=false)[1];\n",
    "myDataB = readtable(\"C:/Users/subha/Desktop/ML - HW 2/sparseB2.csv\",header=false)[1];\n",
    "\n",
    "betaTrue = Array{Float64}(myDataB);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A)  Run the cutting plane algorithm provided for sparse linear regression, finding the best sparsity k through validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "using MLDataUtils\n",
    "srand(1)\n",
    "(train_X, train_Y), (test_X, test_Y) = splitobs(shuffleobs((myDataX,myDataY)), at=.5);\n",
    "(train_X, train_Y), (vl_X, vl_Y) = splitobs(shuffleobs((train_X,train_Y)), at=.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mabs{T <: Number}(x::AbstractArray{T}) is deprecated, use abs.(x) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1mabs\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::RowVector{Float64,Array{Float64,1}}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1mfit_relaxation!\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::SparseRegression.SparseRegressor, ::Array{Float64,1}, ::Array{Float64,2}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\subha\\Desktop\\ML - HW 2\\SparseRegression.jl:86\u001b[22m\u001b[22m\n",
      " [4] \u001b[1mfit!\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::SparseRegression.SparseRegressor, ::Array{Float64,1}, ::Array{Float64,2}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\subha\\Desktop\\ML - HW 2\\SparseRegression.jl:167\u001b[22m\u001b[22m\n",
      " [5] \u001b[1msparseregression\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\subha\\Desktop\\ML - HW 2\\SparseRegression.jl:226\u001b[22m\u001b[22m [inlined]\n",
      " [6] \u001b[1mmacro expansion\u001b[22m\u001b[22m at \u001b[1m.\\In[37]:14\u001b[22m\u001b[22m [inlined]\n",
      " [7] \u001b[1manonymous\u001b[22m\u001b[22m at \u001b[1m.\\<missing>:?\u001b[22m\u001b[22m\n",
      " [8] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\loading.jl:515\u001b[22m\u001b[22m\n",
      " [9] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\subha\\.julia\\v0.6\\Compat\\src\\Compat.jl:407\u001b[22m\u001b[22m\n",
      " [10] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\subha\\.julia\\v0.6\\IJulia\\src\\execute_request.jl:154\u001b[22m\u001b[22m\n",
      " [11] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\subha\\.julia\\v0.6\\IJulia\\src\\eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [12] \u001b[1m(::IJulia.##14#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[37], in expression starting on line 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\r\n",
      "Optimize a model with 2 rows, 101 columns and 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [6e-04, 4e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  Bounds range     [1e+00, 1e+00]\r\n",
      "  RHS range        [3e+00, 4e+00]\r\n",
      "Presolve time: 0.00s\r\n",
      "Presolved: 2 rows, 101 columns, 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "\r\n",
      "Root relaxation: objective 0.000000e+00, 6 iterations, 0.00 seconds\r\n",
      "\r\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\r\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\r\n",
      "\r\n",
      "     0     0    0.00000    0    2          -    0.00000      -     -    0s\r\n",
      "H    0     0                       3.0168783    0.00000   100%     -    0s\r\n",
      "H    0     0                       2.9301944    0.00000   100%     -    0s\r\n",
      "H    0     0                       2.8371528    0.00000   100%     -    0s\r\n",
      "     0     0    0.00000    0    2    2.83715    0.00000   100%     -    0s\r\n",
      "     0     0    0.00000    0    2    2.83715    0.00000   100%     -    0s\r\n",
      "     0     0    0.00000    0    -    2.83715    0.00000   100%     -    0s\r\n",
      "*  226   163               7       2.7034052    0.00000   100%   2.6    0s\r\n",
      "*  957   464               4       2.3670309    0.00000   100%   2.3    0s\r\n",
      "* 4390  1797              20       2.3301632    0.36374  84.4%   3.2    3s\r\n",
      "  7429  3371     cutoff   20         2.33016    0.89503  61.6%   3.7    5s\r\n",
      "* 9737  3728              20       2.1901218    1.16372  46.9%   3.9    7s\r\n",
      " 12190  3905     cutoff   26         2.19012    1.43372  34.5%   4.2   10s\r\n",
      " 15810  3155    2.07918   35   15    2.19012    1.72884  21.1%   4.5   15s\r\n",
      " 19592   758     cutoff   27         2.19012    2.06282  5.81%   4.5   20s\r\n",
      "\r\n",
      "Cutting planes:\r\n",
      "  MIR: 2\r\n",
      "  Lazy constraints: 1376\r\n",
      "\r\n",
      "Explored 20357 nodes (88550 simplex iterations) in 20.50 seconds\r\n",
      "Thread count was 4 (of 4 available processors)\r\n",
      "\r\n",
      "Solution count 7: 2.19012 2.33016 2.36703 ... 3.01688\r\n",
      "\r\n",
      "Optimal solution found (tolerance 1.00e-02)\r\n",
      "Best objective 2.190121826031e+00, best bound 2.169851694550e+00, gap 0.9255%\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Optimize a model with 2 rows, 101 columns and 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [4e-04, 6e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  Bounds range     [1e+00, 1e+00]\r\n",
      "  RHS range        [3e+00, 6e+00]\r\n",
      "Presolve time: 0.00s\r\n",
      "Presolved: 2 rows, 101 columns, 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "\r\n",
      "Root relaxation: objective 0.000000e+00, 8 iterations, 0.00 seconds\r\n",
      "\r\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\r\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\r\n",
      "\r\n",
      "     0     0    0.00000    0    2          -    0.00000      -     -    0s\r\n",
      "H    0     0                       2.9804356    0.00000   100%     -    0s\r\n",
      "H    0     0                       2.9444302    0.00000   100%     -    0s\r\n",
      "H    0     0                       2.3472430    0.00000   100%     -    0s\r\n",
      "     0     0    0.00000    0    3    2.34724    0.00000   100%     -    0s\r\n",
      "     0     0    0.00000    0    4    2.34724    0.00000   100%     -    0s\r\n",
      "     0     2    0.00000    0    4    2.34724    0.00000   100%     -    0s\r\n",
      "*   36    18               8       1.8089615    0.00000   100%   1.3    0s\r\n",
      "*   49    30               9       1.6880580    0.00000   100%   1.3    0s\r\n",
      "H 1913  1034                       1.5709273    0.00000   100%   2.1    0s\r\n",
      " 12204  7051    1.52292   54   10    1.57093    0.00000   100%   2.9    5s\r\n",
      " 20950 12549     cutoff   42         1.57093    0.24816  84.2%   3.6   10s\r\n",
      " 27180 16112     cutoff   28         1.57093    0.36778  76.6%   3.9   15s\r\n",
      " 31726 18569    1.42680   55    4    1.57093    0.44051  72.0%   4.2   20s\r\n",
      " 34945 20050     cutoff   57         1.57093    0.48985  68.8%   4.3   25s\r\n",
      " 37659 21321     cutoff   35         1.57093    0.52707  66.4%   4.4   30s\r\n",
      " 40306 22493    1.35932   31    8    1.57093    0.55888  64.4%   4.5   35s\r\n",
      " 42978 23570    1.53395   28    -    1.57093    0.58901  62.5%   4.5   40s\r\n",
      " 43567 23846    1.45387   62    4    1.57093    0.59502  62.1%   4.5   52s\r\n",
      " 43569 23847    0.98652   29    5    1.57093    0.59502  62.1%   4.5   56s\r\n",
      " 43576 23852    1.28949   37    8    1.57093    0.59502  62.1%   4.5   70s\r\n",
      " 43854 23940    0.59502   37    7    1.57093    0.59502  62.1%   4.6   75s\r\n",
      " 44766 24159     cutoff   50         1.57093    0.59502  62.1%   4.6   80s\r\n",
      " 46225 24570    1.35811   44   11    1.57093    0.59502  62.1%   4.7   85s\r\n",
      " 47843 24872    1.35978   46    9    1.57093    0.59502  62.1%   4.8   90s\r\n",
      " 49418 25165    1.25116   48   15    1.57093    0.59502  62.1%   4.9   95s\r\n",
      " 51375 25529    1.18386   46   13    1.57093    0.59502  62.1%   5.0  100s\r\n",
      " 52684 25749    1.50244   58    8    1.57093    0.59502  62.1%   5.1  106s\r\n",
      " 53894 25891    1.40464   52   11    1.57093    0.59502  62.1%   5.1  111s\r\n",
      " 55386 26046     cutoff   46         1.57093    0.59502  62.1%   5.2  115s\r\n",
      " 56789 26225    1.34681   46   12    1.57093    0.59502  62.1%   5.2  120s\r\n",
      " 58472 26404    1.19763   39    7    1.57093    0.59502  62.1%   5.3  125s\r\n",
      " 60051 26585 infeasible   49         1.57093    0.59524  62.1%   5.3  130s\r\n",
      " 61710 26723     cutoff   46         1.57093    0.62345  60.3%   5.4  135s\r\n",
      " 63266 26863    1.27270   37    9    1.57093    0.65356  58.4%   5.4  141s\r\n",
      " 64777 27039 infeasible   38         1.57093    0.67553  57.0%   5.4  146s\r\n",
      " 66277 27163 infeasible   44         1.57093    0.69633  55.7%   5.5  151s\r\n",
      " 67653 27240     cutoff   52         1.57093    0.71415  54.5%   5.5  156s\r\n",
      " 68662 27214    1.54711   49    5    1.57093    0.72747  53.7%   5.5  160s\r\n",
      " 70124 27227     cutoff   45         1.57093    0.75181  52.1%   5.5  165s\r\n",
      " 71494 27293     cutoff   46         1.57093    0.76954  51.0%   5.6  171s\r\n",
      " 72495 27312     cutoff   43         1.57093    0.78090  50.3%   5.6  175s\r\n",
      " 74017 27332     cutoff   36         1.57093    0.79545  49.4%   5.6  181s\r\n",
      " 75102 27344     cutoff   48         1.57093    0.80948  48.5%   5.6  185s\r\n",
      " 76560 27344     cutoff   45         1.57093    0.82484  47.5%   5.7  191s\r\n",
      " 77502 27322     cutoff   45         1.57093    0.83375  46.9%   5.7  195s\r\n",
      " 78809 27280     cutoff   46         1.57093    0.84921  45.9%   5.7  201s\r\n",
      " 79841 27176     cutoff   44         1.57093    0.85855  45.3%   5.7  212s\r\n",
      " 80162 27154    1.15638   43   10    1.57093    0.86080  45.2%   5.7  215s\r\n",
      " 81395 27039     cutoff   47         1.57093    0.87280  44.4%   5.8  221s\r\n",
      " 82385 26942 infeasible   35         1.57093    0.88315  43.8%   5.8  226s\r\n",
      " 83311 26850     cutoff   53         1.57093    0.89024  43.3%   5.8  230s\r\n",
      " 84421 26717     cutoff   47         1.57093    0.90000  42.7%   5.8  235s\r\n",
      " 85459 26558    1.21574   41   16    1.57093    0.90849  42.2%   5.8  240s\r\n",
      " 86472 26406    1.29860   44   10    1.57093    0.91592  41.7%   5.9  246s\r\n",
      " 87167 26349    1.23644   48   15    1.57093    0.92116  41.4%   5.9  250s\r\n",
      " 88245 26226     cutoff   46         1.57093    0.93094  40.7%   5.9  256s\r\n",
      " 88806 26127    1.38045   47    6    1.57093    0.93612  40.4%   5.9  260s\r\n",
      " 89871 25951 infeasible   37         1.57093    0.94471  39.9%   5.9  266s\r\n",
      " 90977 25762    1.44743   47   13    1.57093    0.95420  39.3%   5.9  271s\r\n",
      " 91741 25613     cutoff   49         1.57093    0.96122  38.8%   5.9  275s\r\n",
      " 92806 25449     cutoff   44         1.57093    0.96952  38.3%   6.0  281s\r\n",
      " 93563 25292     cutoff   44         1.57093    0.97413  38.0%   6.0  285s\r\n",
      " 94630 25095     cutoff   49         1.57093    0.98469  37.3%   6.0  291s\r\n",
      " 95354 24973     cutoff   43         1.57093    0.99054  36.9%   6.0  295s\r\n",
      " 96036 24863    1.30972   46   11    1.57093    0.99572  36.6%   6.0  300s\r\n",
      " 96773 24703 infeasible   47         1.57093    1.00115  36.3%   6.0  305s\r\n",
      " 97888 24442     cutoff   45         1.57093    1.01079  35.7%   6.0  312s\r\n",
      " 98664 24249     cutoff   42         1.57093    1.01724  35.2%   6.1  316s\r\n",
      " 99403 24067    1.36260   46    5    1.57093    1.02301  34.9%   6.1  321s\r\n",
      " 100182 23893     cutoff   52         1.57093    1.02857  34.5%   6.1  325s\r\n",
      " 100954 23673    1.21306   45    8    1.57093    1.03396  34.2%   6.1  330s\r\n",
      " 102151 23398     cutoff   45         1.57093    1.04209  33.7%   6.1  337s\r\n",
      " 102848 23208 infeasible   50         1.57093    1.04598  33.4%   6.1  341s\r\n",
      " 103533 23061     cutoff   64         1.57093    1.05045  33.1%   6.1  346s\r\n",
      " 104218 22895     cutoff   39         1.57093    1.05434  32.9%   6.1  351s\r\n",
      " 104944 22698     cutoff   48         1.57093    1.05871  32.6%   6.1  356s\r\n",
      " 105682 22487    1.30757   43    3    1.57093    1.06344  32.3%   6.2  360s\r\n",
      " 106361 22292     cutoff   48         1.57093    1.06762  32.0%   6.2  365s\r\n",
      " 107126 22067     cutoff   42         1.57093    1.07265  31.7%   6.2  370s\r\n",
      " 107886 21829     cutoff   44         1.57093    1.07789  31.4%   6.2  375s\r\n",
      " 108646 21621    1.43256   44    8    1.57093    1.08223  31.1%   6.2  380s\r\n",
      " 109797 21237 infeasible   44         1.57093    1.08997  30.6%   6.2  387s\r\n",
      " 110586 21019    1.38132   44   13    1.57093    1.09454  30.3%   6.2  392s\r\n",
      " 111329 20767     cutoff   47         1.57093    1.09948  30.0%   6.2  397s\r\n",
      " 111745 20639     cutoff   49         1.57093    1.10125  29.9%   6.2  400s\r\n",
      " 112497 20406 infeasible   36         1.57093    1.10603  29.6%   6.2  405s\r\n",
      " 113685 20008    1.38858   45   17    1.57093    1.11342  29.1%   6.2  412s\r\n",
      " 114423 19784     cutoff   44         1.57093    1.11784  28.8%   6.2  417s\r\n",
      " 115143 19542     cutoff   48         1.57093    1.12249  28.5%   6.3  422s\r\n",
      " 115867 19560     cutoff   44         1.57093    1.12706  28.3%   6.3  427s\r\n",
      " 116558 19599    1.47671   46   15    1.57093    1.12967  28.1%   6.3  432s\r\n",
      " 116932 19593     cutoff   46         1.57093    1.13150  28.0%   6.3  435s\r\n",
      " 117671 19588    1.56280   48   15    1.57093    1.13567  27.7%   6.3  440s\r\n",
      " 118407 19578     cutoff   39         1.57093    1.13967  27.5%   6.3  445s\r\n",
      " 119140 19569     cutoff   39         1.57093    1.14294  27.2%   6.3  450s\r\n",
      " 119951 19518     cutoff   45         1.57093    1.14704  27.0%   6.3  455s\r\n",
      " 120678 19460     cutoff   40         1.57093    1.15178  26.7%   6.3  460s\r\n",
      " 121439 19431     cutoff   45         1.57093    1.15579  26.4%   6.3  465s\r\n",
      " 122181 19389    1.57083   47    9    1.57093    1.15983  26.2%   6.3  470s\r\n",
      " 122925 19293     cutoff   41         1.57093    1.16391  25.9%   6.3  475s\r\n",
      " 123704 19251     cutoff   56         1.57093    1.16724  25.7%   6.3  480s\r\n",
      " 124410 19211    1.43689   43    9    1.57093    1.17081  25.5%   6.4  485s\r\n",
      " 125103 19136     cutoff   45         1.57093    1.17498  25.2%   6.4  490s\r\n",
      " 125821 19140     cutoff   51         1.57093    1.17795  25.0%   6.4  495s\r\n",
      " 126429 19060 infeasible   46         1.57093    1.18195  24.8%   6.4  500s\r\n",
      " 127128 18977 infeasible   41         1.57093    1.18580  24.5%   6.4  505s\r\n",
      " 127837 18902    1.33405   46   10    1.57093    1.18992  24.3%   6.4  510s\r\n",
      " 128565 18878     cutoff   45         1.57093    1.19411  24.0%   6.4  525s\r\n",
      " 129107 18757     cutoff   38         1.57093    1.19701  23.8%   6.4  530s\r\n",
      " 129800 18697     cutoff   48         1.57093    1.20006  23.6%   6.4  535s\r\n",
      " 130494 18613    1.56623   54    6    1.57093    1.20414  23.3%   6.4  541s\r\n",
      " 131246 18510 infeasible   40         1.57093    1.20783  23.1%   6.4  546s\r\n",
      " 131899 18395     cutoff   43         1.57093    1.21141  22.9%   6.4  551s\r\n",
      " 132600 18309     cutoff   45         1.57093    1.21509  22.7%   6.4  555s\r\n",
      " 133496 18134     cutoff   42         1.57093    1.22011  22.3%   6.4  561s\r\n",
      " 134160 18047    1.44848   41    3    1.57093    1.22363  22.1%   6.4  566s\r\n",
      " 134866 17950    1.54308   40    4    1.57093    1.22683  21.9%   6.4  571s\r\n",
      " 135557 17842     cutoff   41         1.57093    1.23064  21.7%   6.4  576s\r\n",
      " 136204 17736     cutoff   43         1.57093    1.23375  21.5%   6.4  581s\r\n",
      " 136905 17629     cutoff   44         1.57093    1.23700  21.3%   6.4  587s\r\n",
      " 137228 17572    1.48592   43    3    1.57093    1.23883  21.1%   6.4  590s\r\n",
      " 137897 17482     cutoff   42         1.57093    1.24220  20.9%   6.4  595s\r\n",
      " 138550 17396 infeasible   39         1.57093    1.24566  20.7%   6.4  600s\r\n",
      "\r\n",
      "Cutting planes:\r\n",
      "  MIR: 1\r\n",
      "  Flow cover: 3\r\n",
      "  Lazy constraints: 2644\r\n",
      "\r\n",
      "Explored 138692 nodes (894222 simplex iterations) in 600.05 seconds\r\n",
      "Thread count was 4 (of 4 available processors)\r\n",
      "\r\n",
      "Solution count 6: 1.57093 1.68806 1.80896 ... 2.98044\r\n",
      "\r\n",
      "Time limit reached\r\n",
      "Best objective 1.570927257071e+00, best bound 1.246440557202e+00, gap 20.6557%\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mNot solved to optimality, status: UserLimit\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\r\n",
      "Optimize a model with 2 rows, 101 columns and 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [7e-08, 5e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  Bounds range     [1e+00, 1e+00]\r\n",
      "  RHS range        [2e+00, 8e+00]\r\n",
      "Presolve time: 0.00s\r\n",
      "Presolved: 2 rows, 101 columns, 200 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "\r\n",
      "Root relaxation: objective 0.000000e+00, 6 iterations, 0.00 seconds\r\n",
      "\r\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\r\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\r\n",
      "\r\n",
      "     0     0    0.00000    0    4          -    0.00000      -     -    0s\r\n",
      "H    0     0                       1.6696983    0.00000   100%     -    0s\r\n",
      "H    0     0                       1.4182496    0.00000   100%     -    0s\r\n",
      "H    0     0                       1.0451342    0.00000   100%     -    0s\r\n",
      "     0     0    0.00000    0    3    1.04513    0.00000   100%     -    0s\r\n",
      "     0     0    0.00000    0    2    1.04513    0.00000   100%     -    0s\r\n",
      "     0     0    0.00000    0    6    1.04513    0.00000   100%     -    0s\r\n",
      "     0     0    0.00000    0    2    1.04513    0.00000   100%     -    0s\r\n",
      "     0     2    0.00000    0    2    1.04513    0.00000   100%     -    0s\r\n",
      " 10931  6366     cutoff   76         1.04513    0.00000   100%   3.0    5s\r\n",
      " 20270 13119     cutoff   32         1.04513    0.00000   100%   3.6   10s\r\n",
      " 25474 16863    0.97506   49   13    1.04513    0.00000   100%   4.1   16s\r\n",
      " 30614 20076     cutoff   72         1.04513    0.05609  94.6%   4.2   20s\r\n",
      " 37273 24215    0.55984   25    9    1.04513    0.10446  90.0%   4.4   25s\r\n",
      " 42746 27574    0.72914   29   14    1.04513    0.12840  87.7%   4.5   30s\r\n",
      " 48616 31003    0.93170   68    6    1.04513    0.15500  85.2%   4.5   35s\r\n",
      " 53063 33475    0.68881   38    2    1.04513    0.17476  83.3%   4.6   48s\r\n",
      " 53065 33476    0.36525   31    8    1.04513    0.17476  83.3%   4.6   50s\r\n",
      " 53077 33487    0.17476   28    4    1.04513    0.17476  83.3%   4.6   55s\r\n",
      " 54463 33973    0.30449   40   11    1.04513    0.17476  83.3%   4.7   60s\r\n",
      " 58652 35447    0.45629   49   12    1.04513    0.17476  83.3%   4.8   65s\r\n",
      " 62430 36698    0.78764   48   10    1.04513    0.17476  83.3%   4.8   70s\r\n",
      " 65884 37731     cutoff  104         1.04513    0.17476  83.3%   4.9   75s\r\n",
      " 69060 38711    0.91227   59    2    1.04513    0.17476  83.3%   5.0   83s\r\n",
      " 70116 39013     cutoff  105         1.04513    0.17476  83.3%   5.0   85s\r\n",
      " 73284 39779    0.67007   46   12    1.04513    0.17476  83.3%   5.0   90s\r\n",
      " 76551 40694     cutoff   88         1.04513    0.19490  81.4%   5.1   95s\r\n",
      " 79596 41587     cutoff   89         1.04513    0.21435  79.5%   5.1  100s\r\n",
      " 82488 42504    0.92775   77    -    1.04513    0.23044  78.0%   5.2  105s\r\n",
      " 85335 43264    0.98440   67    5    1.04513    0.24724  76.3%   5.2  110s\r\n",
      " 87757 43842    0.47331   38   13    1.04513    0.26059  75.1%   5.2  115s\r\n",
      " 90679 44637     cutoff   95         1.04513    0.27415  73.8%   5.3  120s\r\n",
      " 93186 45372    0.63264   46   14    1.04513    0.28670  72.6%   5.3  125s\r\n",
      " 95695 46006     cutoff   56         1.04513    0.29724  71.6%   5.3  130s\r\n",
      " 98055 46574    0.78270   46    7    1.04513    0.30566  70.8%   5.3  135s\r\n",
      " 100693 47194     cutoff   51         1.04513    0.31527  69.8%   5.3  140s\r\n",
      " 103124 47643     cutoff  106         1.04513    0.32378  69.0%   5.4  145s\r\n",
      " 105254 48122     cutoff   97         1.04513    0.33090  68.3%   5.4  150s\r\n",
      " 107702 48691     cutoff   52         1.04513    0.33896  67.6%   5.4  155s\r\n",
      " 109899 49169     cutoff   95         1.04513    0.34495  67.0%   5.4  160s\r\n",
      " 112338 49609     cutoff   49         1.04513    0.35135  66.4%   5.4  165s\r\n",
      " 114587 50029    0.89971   48    3    1.04513    0.35738  65.8%   5.4  170s\r\n",
      " 116536 50468     cutoff   90         1.04513    0.36211  65.4%   5.5  175s\r\n",
      " 118847 50896     cutoff   65         1.04513    0.36820  64.8%   5.5  180s\r\n",
      " 121181 51341     cutoff   70         1.04513    0.37467  64.2%   5.5  185s\r\n",
      " 122609 51636     cutoff   75         1.04513    0.37843  63.8%   5.5  190s\r\n",
      " 124624 51993    0.60829   44    6    1.04513    0.38268  63.4%   5.5  195s\r\n",
      " 126633 52192     cutoff   81         1.04513    0.38630  63.0%   5.5  200s\r\n",
      " 128528 52518     cutoff   56         1.04513    0.39023  62.7%   5.5  205s\r\n",
      " 130169 52760    0.75050   46   19    1.04513    0.39353  62.3%   5.5  210s\r\n",
      " 132452 53064    0.98717   51    -    1.04513    0.39744  62.0%   5.5  215s\r\n",
      " 133957 53235    0.51860   40   18    1.04513    0.40084  61.6%   5.6  220s\r\n",
      " 135809 53556    0.78298   44    4    1.04513    0.40523  61.2%   5.6  226s\r\n",
      " 136787 53748    1.00211   50    -    1.04513    0.40730  61.0%   5.6  230s\r\n",
      " 138885 54136    0.79032   44    3    1.04513    0.41156  60.6%   5.6  235s\r\n",
      " 140635 54444 infeasible   47         1.04513    0.41481  60.3%   5.6  240s\r\n",
      " 142653 54771     cutoff   45         1.04513    0.41870  59.9%   5.6  245s\r\n",
      " 144257 54938    0.72333   46    5    1.04513    0.42203  59.6%   5.6  250s\r\n",
      " 145694 55155    0.98476   45    7    1.04513    0.42459  59.4%   5.6  255s\r\n",
      " 147569 55385     cutoff   83         1.04513    0.42846  59.0%   5.7  260s\r\n",
      " 149237 55532     cutoff   71         1.04513    0.43279  58.6%   5.7  265s\r\n",
      " 150939 55746     cutoff   66         1.04513    0.43610  58.3%   5.7  270s\r\n",
      " 152763 56043     cutoff   50         1.04513    0.43942  58.0%   5.7  275s\r\n",
      " 154463 56457    0.54378   42   13    1.04513    0.44336  57.6%   5.7  280s\r\n",
      " 156128 57195     cutoff   72         1.04513    0.44588  57.3%   5.7  285s\r\n",
      " 158157 58121    0.82719   51    2    1.04513    0.44908  57.0%   5.7  290s\r\n",
      " 159777 58889    0.58491   43   12    1.04513    0.45167  56.8%   5.7  295s\r\n",
      " 161344 59648    0.67656   50   11    1.04513    0.45433  56.5%   5.7  302s\r\n",
      " 161797 59841     cutoff   38         1.04513    0.45508  56.5%   5.7  305s\r\n",
      " 163436 60602    0.93952   49   11    1.04513    0.45813  56.2%   5.7  310s\r\n",
      " 165014 61303    0.85910   41   13    1.04513    0.46053  55.9%   5.7  315s\r\n",
      " 166840 62176    0.83793   44    4    1.04513    0.46382  55.6%   5.7  320s\r\n",
      " 168323 62782     cutoff   68         1.04513    0.46621  55.4%   5.7  325s\r\n",
      " 170276 63666     cutoff   85         1.04513    0.46898  55.1%   5.8  331s\r\n",
      " 171449 64215     cutoff   47         1.04513    0.47047  55.0%   5.8  335s\r\n",
      " 173305 64974     cutoff   42         1.04513    0.47279  54.8%   5.8  340s\r\n",
      " 174564 65527    0.77378   52   12    1.04513    0.47485  54.6%   5.8  345s\r\n",
      " 175922 66087    0.78930   52    9    1.04513    0.47690  54.4%   5.8  350s\r\n",
      " 177282 66615    0.95061   48    8    1.04513    0.47837  54.2%   5.8  355s\r\n",
      " 178765 67208     cutoff   48         1.04513    0.48076  54.0%   5.8  360s\r\n",
      " 180205 67809    0.77221   45    9    1.04513    0.48314  53.8%   5.8  365s\r\n",
      " 181727 68466    0.96497   46    9    1.04513    0.48587  53.5%   5.8  371s\r\n",
      " 183271 69119     cutoff   48         1.04513    0.48822  53.3%   5.8  376s\r\n",
      " 184398 69496 infeasible   48         1.04513    0.48979  53.1%   5.8  380s\r\n",
      " 185746 69988     cutoff   79         1.04513    0.49190  52.9%   5.8  385s\r\n",
      " 187082 70455    1.03675   54   14    1.04513    0.49371  52.8%   5.8  390s\r\n",
      " 188580 71052     cutoff   58         1.04513    0.49593  52.5%   5.9  395s\r\n",
      " 189264 71357     cutoff   50         1.04513    0.49710  52.4%   5.9  402s\r\n",
      " 190209 71642    0.91619   53    9    1.04513    0.49884  52.3%   5.9  406s\r\n",
      " 191021 71929    0.91885   47   22    1.04513    0.50008  52.2%   5.9  410s\r\n",
      " 192374 72406     cutoff   56         1.04513    0.50177  52.0%   5.9  416s\r\n",
      " 193740 72927 infeasible   48         1.04513    0.50352  51.8%   5.9  420s\r\n",
      " 194926 73399    0.94999   54   10    1.04513    0.50489  51.7%   5.9  425s\r\n",
      " 196269 73936     cutoff   48         1.04513    0.50663  51.5%   5.9  430s\r\n",
      " 197560 74415    0.85473   48    9    1.04513    0.50862  51.3%   5.9  436s\r\n",
      " 198690 74752    0.88125   47    7    1.04513    0.51036  51.2%   5.9  440s\r\n",
      " 199603 74924    0.91567   51   12    1.04513    0.51212  51.0%   5.9  445s\r\n",
      " 200657 75146    0.92165   47   14    1.04513    0.51401  50.8%   5.9  450s\r\n",
      " 202124 75542    0.91233   40    4    1.04513    0.51627  50.6%   6.0  456s\r\n",
      " 203318 75827     cutoff   68         1.04513    0.51810  50.4%   6.0  461s\r\n",
      " 204307 76021     cutoff   54         1.04513    0.52011  50.2%   6.0  466s\r\n",
      " 205367 76277     cutoff   59         1.04513    0.52223  50.0%   6.0  471s\r\n",
      " 206289 76454     cutoff   47         1.04513    0.52440  49.8%   6.0  476s\r\n",
      " 207124 76639    0.94545   51   12    1.04513    0.52605  49.7%   6.0  480s\r\n",
      " 208183 76888    0.91095   45   10    1.04513    0.52775  49.5%   6.0  485s\r\n",
      " 209260 77100    0.62989   40   13    1.04513    0.52969  49.3%   6.0  490s\r\n",
      " 210286 77275     cutoff   42         1.04513    0.53142  49.2%   6.1  495s\r\n",
      " 211400 77490    0.98484   48   26    1.04513    0.53315  49.0%   6.1  501s\r\n",
      " 211978 77595    1.03775   52   16    1.04513    0.53405  48.9%   6.1  505s\r\n",
      " 213100 77851     cutoff   47         1.04513    0.53584  48.7%   6.1  510s\r\n",
      " 214284 78109     cutoff   47         1.04513    0.53793  48.5%   6.1  516s\r\n",
      " 215135 78319    1.03514   51    -    1.04513    0.53935  48.4%   6.1  520s\r\n",
      " 215932 78465     cutoff   60         1.04513    0.54052  48.3%   6.1  525s\r\n",
      " 217095 78676     cutoff   46         1.04513    0.54269  48.1%   6.1  531s\r\n",
      " 217811 78794     cutoff   54         1.04513    0.54347  48.0%   6.2  535s\r\n",
      " 218970 79003     cutoff   49         1.04513    0.54556  47.8%   6.2  541s\r\n",
      " 219849 79225     cutoff   49         1.04513    0.54683  47.7%   6.2  545s\r\n",
      " 220952 79368     cutoff   43         1.04513    0.54897  47.5%   6.2  551s\r\n",
      " 221711 79492     cutoff   48         1.04513    0.55030  47.3%   6.2  555s\r\n",
      " 222802 79667     cutoff   46         1.04513    0.55216  47.2%   6.2  560s\r\n",
      " 223882 79820     cutoff   49         1.04513    0.55372  47.0%   6.2  567s\r\n",
      " 224280 79886     cutoff   46         1.04513    0.55461  46.9%   6.2  572s\r\n",
      " 224782 79934    0.92704   47   18    1.04513    0.55540  46.9%   6.2  576s\r\n",
      " 225545 80092     cutoff   44         1.04513    0.55626  46.8%   6.2  580s\r\n",
      " 226682 80205    0.92099   43    8    1.04513    0.55800  46.6%   6.3  587s\r\n",
      " 227379 80298    0.79583   43   10    1.04513    0.55912  46.5%   6.3  591s\r\n",
      " 228139 80436    0.91960   49   15    1.04513    0.56035  46.4%   6.3  595s\r\n",
      " 228921 80541    0.90412   51   13    1.04513    0.56163  46.3%   6.3  600s\r\n",
      "\r\n",
      "Cutting planes:\r\n",
      "  Flow cover: 2\r\n",
      "  Lazy constraints: 2021\r\n",
      "\r\n",
      "Explored 229273 nodes (1441431 simplex iterations) in 600.03 seconds\r\n",
      "Thread count was 4 (of 4 available processors)\r\n",
      "\r\n",
      "Solution count 3: 1.04513 1.41825 1.6697 \r\n",
      "\r\n",
      "Time limit reached\r\n",
      "Best objective 1.045134224724e+00, best bound 5.620602155551e-01, gap 46.2212%\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mNot solved to optimality, status: UserLimit\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\r\n",
      "Optimize a model with 2 rows, 101 columns and 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [1e-08, 1e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  Bounds range     [1e+00, 1e+00]\r\n",
      "  RHS range        [1e+00, 1e+01]\r\n",
      "Presolve time: 0.00s\r\n",
      "Presolved: 2 rows, 101 columns, 200 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Found heuristic solution: objective 0.6308883\r\n",
      "\r\n",
      "Root relaxation: objective 2.867514e-01, 13 iterations, 0.00 seconds\r\n",
      "\r\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\r\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\r\n",
      "\r\n",
      "     0     0    0.28675    0    2    0.63089    0.28675  54.5%     -    0s\r\n",
      "     0     0    0.28854    0    3    0.63089    0.28854  54.3%     -    0s\r\n",
      "     0     0    0.29144    0    6    0.63089    0.29144  53.8%     -    0s\r\n",
      "     0     0    0.29630    0    6    0.63089    0.29630  53.0%     -    0s\r\n",
      "     0     0    0.29666    0    6    0.63089    0.29666  53.0%     -    0s\r\n",
      "     0     0    0.29685    0    7    0.63089    0.29685  52.9%     -    0s\r\n",
      "     0     0    0.29686    0    7    0.63089    0.29686  52.9%     -    0s\r\n",
      "     0     0    0.29691    0    7    0.63089    0.29691  52.9%     -    0s\r\n",
      "     0     2    0.29691    0    7    0.63089    0.29691  52.9%     -    0s\r\n",
      " 15058  9866     cutoff   48         0.63089    0.36357  42.4%   2.8    5s\r\n",
      " 24926 15932    0.48687   37    7    0.63089    0.37637  40.3%   3.2   12s\r\n",
      " 24937 15939    0.47876   29   13    0.63089    0.37637  40.3%   3.2   27s\r\n",
      " 24940 15946    0.37637   24   12    0.63089    0.37637  40.3%   3.3   30s\r\n",
      " 30506 17832    0.57168   53    7    0.63089    0.39813  36.9%   3.4   35s\r\n",
      " 37586 19972     cutoff   54         0.63089    0.41619  34.0%   3.6   40s\r\n",
      " 43418 21480     cutoff   41         0.63089    0.42531  32.6%   3.7   45s\r\n",
      " 48724 22618     cutoff   57         0.63089    0.43215  31.5%   3.8   50s\r\n",
      " 52617 23271     cutoff   54         0.63089    0.43675  30.8%   3.9   55s\r\n",
      " 56782 23830     cutoff   54         0.63089    0.44110  30.1%   4.0   60s\r\n",
      " 60740 24292 infeasible   50         0.63089    0.44536  29.4%   4.1   65s\r\n",
      " 64515 24613     cutoff   45         0.63089    0.44871  28.9%   4.2   70s\r\n",
      " 67699 24724     cutoff   41         0.63089    0.45235  28.3%   4.3   75s\r\n",
      " 71372 24748     cutoff   40         0.63089    0.45500  27.9%   4.4   80s\r\n",
      " 74574 25437    0.56080   39    -    0.63089    0.45783  27.4%   4.5   85s\r\n",
      " 77810 26580    0.61757   39    3    0.63089    0.46043  27.0%   4.5   90s\r\n",
      " 80680 27541     cutoff   43         0.63089    0.46281  26.6%   4.6   95s\r\n",
      " 83826 28511    0.54671   40   11    0.63089    0.46542  26.2%   4.6  100s\r\n",
      " 86582 29339     cutoff   42         0.63089    0.46759  25.9%   4.7  105s\r\n",
      " 88090 29761     cutoff   47         0.63089    0.46869  25.7%   4.7  110s\r\n",
      " 90714 30443     cutoff   48         0.63089    0.47078  25.4%   4.8  115s\r\n",
      " 93619 31287     cutoff   48         0.63089    0.47291  25.0%   4.8  120s\r\n",
      " 96309 31939    0.62091   44   14    0.63089    0.47505  24.7%   4.9  125s\r\n",
      " 98936 32579    0.55450   41   13    0.63089    0.47699  24.4%   4.9  130s\r\n",
      " 101556 33218    0.62064   45    3    0.63089    0.47866  24.1%   5.0  135s\r\n",
      " 104090 33769    0.58355   37   11    0.63089    0.48067  23.8%   5.0  140s\r\n",
      " 106615 34259     cutoff   42         0.63089    0.48232  23.5%   5.1  145s\r\n",
      " 108955 34740    0.53122   37    5    0.63089    0.48379  23.3%   5.1  150s\r\n",
      " 111629 35274    0.62458   40   17    0.63089    0.48556  23.0%   5.1  155s\r\n",
      " 113806 35599    0.58392   36    8    0.63089    0.48682  22.8%   5.2  160s\r\n",
      " 116376 36027     cutoff   50         0.63089    0.48856  22.6%   5.2  165s\r\n",
      " 118658 36394    0.55650   39    9    0.63089    0.49006  22.3%   5.3  170s\r\n",
      " 120929 36750     cutoff   38         0.63089    0.49134  22.1%   5.3  175s\r\n",
      " 123232 37114    0.54366   37   11    0.63089    0.49259  21.9%   5.3  180s\r\n",
      " 123607 37217     cutoff   47         0.63089    0.49272  21.9%   5.3  186s\r\n",
      " 124764 37331     cutoff   48         0.63089    0.49331  21.8%   5.4  190s\r\n",
      " 127030 37596     cutoff   39         0.63089    0.49486  21.6%   5.4  195s\r\n",
      " 128873 37792    0.57447   39    8    0.63089    0.49582  21.4%   5.4  200s\r\n",
      " 131151 38008     cutoff   41         0.63089    0.49726  21.2%   5.5  205s\r\n",
      " 133087 38182    0.60959   40    2    0.63089    0.49857  21.0%   5.5  210s\r\n",
      " 135110 38363     cutoff   40         0.63089    0.49983  20.8%   5.5  215s\r\n",
      " 137459 38580     cutoff   44         0.63089    0.50128  20.5%   5.5  220s\r\n",
      " 139370 38765    0.58575   41   13    0.63089    0.50236  20.4%   5.6  225s\r\n",
      " 141293 38915    0.61485   38   20    0.63089    0.50351  20.2%   5.6  230s\r\n",
      " 143300 39060    0.61710   38   12    0.63089    0.50476  20.0%   5.6  235s\r\n",
      " 145276 39221     cutoff   38         0.63089    0.50576  19.8%   5.7  240s\r\n",
      " 147480 39352    0.56456   37   10    0.63089    0.50707  19.6%   5.7  245s\r\n",
      " 149333 39416    0.61626   42   14    0.63089    0.50801  19.5%   5.7  250s\r\n",
      " 151254 39509    0.55232   37    8    0.63089    0.50906  19.3%   5.7  255s\r\n",
      " 153249 39542    0.59831   39    6    0.63089    0.51026  19.1%   5.8  260s\r\n",
      " 155212 39541    0.61537   37    8    0.63089    0.51136  18.9%   5.8  265s\r\n",
      " 157227 39598     cutoff   40         0.63089    0.51247  18.8%   5.8  270s\r\n",
      " 158857 39690     cutoff   43         0.63089    0.51331  18.6%   5.8  275s\r\n",
      " 160863 39772    0.62821   43   13    0.63089    0.51439  18.5%   5.9  280s\r\n",
      " 162803 39770    0.53158   35    6    0.63089    0.51544  18.3%   5.9  285s\r\n",
      " 164308 39807     cutoff   42         0.63089    0.51621  18.2%   5.9  290s\r\n",
      " 166271 39838    0.55510   38   14    0.63089    0.51720  18.0%   5.9  295s\r\n",
      " 168116 39829    0.57179   37   12    0.63089    0.51822  17.9%   5.9  300s\r\n",
      " 170099 39853     cutoff   46         0.63089    0.51924  17.7%   6.0  305s\r\n",
      " 171613 39830    0.61553   38    7    0.63089    0.52006  17.6%   6.0  310s\r\n",
      " 173579 39846    0.57575   40   13    0.63089    0.52102  17.4%   6.0  315s\r\n",
      " 175188 39789     cutoff   40         0.63089    0.52178  17.3%   6.0  320s\r\n",
      " 177159 39747     cutoff   40         0.63089    0.52272  17.1%   6.0  325s\r\n",
      " 178624 39665     cutoff   47         0.63089    0.52344  17.0%   6.1  330s\r\n",
      " 180595 39591     cutoff   42         0.63089    0.52442  16.9%   6.1  335s\r\n",
      " 182068 39501     cutoff   58         0.63089    0.52525  16.7%   6.1  340s\r\n",
      " 183949 39409     cutoff   36         0.63089    0.52618  16.6%   6.1  345s\r\n",
      " 185463 39345    0.56180   36   14    0.63089    0.52701  16.5%   6.1  350s\r\n",
      " 187343 39218     cutoff   43         0.63089    0.52810  16.3%   6.1  355s\r\n",
      " 189195 39118     cutoff   45         0.63089    0.52895  16.2%   6.2  361s\r\n",
      " 190653 39017     cutoff   38         0.63089    0.52969  16.0%   6.2  365s\r\n",
      " 192583 38938     cutoff   41         0.63089    0.53062  15.9%   6.2  370s\r\n",
      " 194132 38923    0.56889   37   13    0.63089    0.53122  15.8%   6.2  376s\r\n",
      " 195303 38788     cutoff   43         0.63089    0.53180  15.7%   6.2  381s\r\n",
      " 196932 38666     cutoff   44         0.63089    0.53257  15.6%   6.2  385s\r\n",
      " 198484 38572    0.60735   41    6    0.63089    0.53336  15.5%   6.2  390s\r\n",
      " 200329 38407     cutoff   40         0.63089    0.53431  15.3%   6.3  395s\r\n",
      " 201926 38309     cutoff   40         0.63089    0.53506  15.2%   6.3  400s\r\n",
      " 203809 38115    0.57293   37   13    0.63089    0.53597  15.0%   6.3  405s\r\n",
      " 205354 37952    0.59606   38   12    0.63089    0.53668  14.9%   6.3  410s\r\n",
      " 206897 37816    0.56141   38    8    0.63089    0.53742  14.8%   6.3  415s\r\n",
      " 208724 37606    0.62467   38   11    0.63089    0.53834  14.7%   6.3  420s\r\n",
      " 210090 37471    0.55670   37   15    0.63089    0.53906  14.6%   6.3  425s\r\n",
      " 211982 37314    0.63050   37   12    0.63089    0.53992  14.4%   6.4  430s\r\n",
      " 213466 37157    0.61577   39   15    0.63089    0.54066  14.3%   6.4  435s\r\n",
      " 215337 36964    0.55483   37   19    0.63089    0.54158  14.2%   6.4  440s\r\n",
      " 216870 36779     cutoff   39         0.63089    0.54229  14.0%   6.4  445s\r\n",
      " 218747 36604     cutoff   39         0.63089    0.54314  13.9%   6.4  451s\r\n",
      " 220251 36477     cutoff   41         0.63089    0.54375  13.8%   6.4  455s\r\n",
      " 221740 36289     cutoff   42         0.63089    0.54448  13.7%   6.4  460s\r\n",
      " 223568 36056     cutoff   58         0.63089    0.54533  13.6%   6.4  465s\r\n",
      " 224857 35899     cutoff   37         0.63089    0.54590  13.5%   6.4  470s\r\n",
      " 226626 35643    0.56561   36   11    0.63089    0.54681  13.3%   6.5  475s\r\n",
      " 228027 35430     cutoff   39         0.63089    0.54748  13.2%   6.5  480s\r\n",
      " 228765 35342     cutoff   43         0.63089    0.54783  13.2%   6.5  485s\r\n",
      " 230235 35151    0.62546   45    8    0.63089    0.54841  13.1%   6.5  490s\r\n",
      " 231726 34952    0.62236   38   15    0.63089    0.54907  13.0%   6.5  495s\r\n",
      " 233441 34665    0.62007   39   11    0.63089    0.54984  12.8%   6.5  500s\r\n",
      " 234825 34477     cutoff   62         0.63089    0.55049  12.7%   6.5  505s\r\n",
      " 236581 34206     cutoff   43         0.63089    0.55132  12.6%   6.5  510s\r\n",
      " 237926 33992     cutoff   38         0.63089    0.55200  12.5%   6.5  515s\r\n",
      " 239736 33692    0.60183   42   13    0.63089    0.55281  12.4%   6.5  521s\r\n",
      " 241099 33471    0.60768   39   14    0.63089    0.55344  12.3%   6.5  525s\r\n",
      " 242793 33157     cutoff   52         0.63089    0.55424  12.1%   6.6  530s\r\n",
      " 244213 32947    0.59391   42   11    0.63089    0.55482  12.1%   6.6  535s\r\n",
      " 245917 32641    0.62846   39   10    0.63089    0.55565  11.9%   6.6  540s\r\n",
      " 247646 32350    0.60529   43   15    0.63089    0.55640  11.8%   6.6  545s\r\n",
      " 249182 32033     cutoff   46         0.63089    0.55719  11.7%   6.6  550s\r\n",
      " 250658 31776     cutoff   42         0.63089    0.55785  11.6%   6.6  555s\r\n",
      " 252533 31392     cutoff   40         0.63089    0.55875  11.4%   6.6  560s\r\n",
      " 254117 31074    0.62067   40    5    0.63089    0.55954  11.3%   6.6  565s\r\n",
      " 255718 30768    0.58554   43    6    0.63089    0.56030  11.2%   6.6  570s\r\n",
      " 257278 30438     cutoff   39         0.63089    0.56109  11.1%   6.6  575s\r\n",
      " 258720 30103    0.56504   39    6    0.63089    0.56183  10.9%   6.6  580s\r\n",
      " 260152 29762     cutoff   42         0.63089    0.56250  10.8%   6.6  585s\r\n",
      " 261993 29355     cutoff   39         0.63089    0.56336  10.7%   6.7  590s\r\n",
      " 263385 29000     cutoff   37         0.63089    0.56409  10.6%   6.7  595s\r\n",
      " 264692 28673    0.63064   37   10    0.63089    0.56477  10.5%   6.7  600s\r\n",
      "\r\n",
      "Cutting planes:\r\n",
      "  Gomory: 1\r\n",
      "  MIR: 4\r\n",
      "  Flow cover: 2\r\n",
      "  Lazy constraints: 1278\r\n",
      "\r\n",
      "Explored 264896 nodes (1766057 simplex iterations) in 600.01 seconds\r\n",
      "Thread count was 4 (of 4 available processors)\r\n",
      "\r\n",
      "Solution count 1: 0.630888 \r\n",
      "\r\n",
      "Time limit reached\r\n",
      "Best objective 6.308883395485e-01, best bound 5.648588781403e-01, gap 10.4661%\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mNot solved to optimality, status: UserLimit\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\r\n",
      "Optimize a model with 2 rows, 101 columns and 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [6e-08, 1e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  Bounds range     [1e+00, 1e+00]\r\n",
      "  RHS range        [1e+00, 1e+01]\r\n",
      "Presolve time: 0.00s\r\n",
      "Presolved: 2 rows, 101 columns, 200 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "\r\n",
      "Root relaxation: objective 2.363862e-01, 9 iterations, 0.00 seconds\r\n",
      "\r\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\r\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\r\n",
      "\r\n",
      "     0     0    0.23639    0    2          -    0.23639      -     -    0s\r\n",
      "H    0     0                       1.9494985    0.23639  87.9%     -    0s\r\n",
      "     0     0    0.24679    0    4    1.94950    0.24679  87.3%     -    0s\r\n",
      "H    0     0                       1.8403648    0.24679  86.6%     -    0s\r\n",
      "H    0     0                       1.5511012    0.24679  84.1%     -    0s\r\n",
      "     0     0    0.25238    0    8    1.55110    0.25238  83.7%     -    0s\r\n",
      "     0     0    0.25251    0    8    1.55110    0.25251  83.7%     -    0s\r\n",
      "     0     0    0.25292    0    8    1.55110    0.25292  83.7%     -    0s\r\n",
      "     0     0    0.25312    0    8    1.55110    0.25312  83.7%     -    0s\r\n",
      "     0     0    0.25387    0    8    1.55110    0.25387  83.6%     -    0s\r\n",
      "     0     2    0.25412    0    8    1.55110    0.25412  83.6%     -    0s\r\n",
      "*  107    91              27       1.4608335    0.26263  82.0%   2.3    0s\r\n",
      "* 1242   817              55       1.3902146    0.27419  80.3%   2.4    1s\r\n",
      "*13757 10587              87       1.2916058    0.30892  76.1%   2.2    4s\r\n",
      " 14724 11381    0.45727   33    2    1.29161    0.30966  76.0%   2.2    5s\r\n",
      " 26577 21117    1.27389  107    -    1.29161    0.31980  75.2%   2.3   10s\r\n",
      " 29353 23457    0.53734   78   11    1.29161    0.32152  75.1%   2.3   15s\r\n",
      " 29374 23471    0.53729   93   14    1.29161    0.32152  75.1%   2.3   20s\r\n",
      " 29375 23472    0.38070   35   14    1.29161    0.32152  75.1%   2.3   25s\r\n",
      "*29995 22577              60       1.2262873    0.32152  73.8%   2.3   28s\r\n",
      " 31415 23227    0.76446   64    5    1.22629    0.32511  73.5%   2.4   30s\r\n",
      " 37336 26088    1.20889  113    2    1.22629    0.33643  72.6%   2.5   35s\r\n",
      "*38722 25552              48       1.1900319    0.33750  71.6%   2.5   36s\r\n",
      "*38725 24157              51       0.9379115    0.33750  64.0%   2.5   36s\r\n",
      " 42405 25919     cutoff   64         0.93791    0.34066  63.7%   2.5   40s\r\n",
      " 48100 28817     cutoff  102         0.93791    0.34465  63.3%   2.6   45s\r\n",
      " 52703 31010     cutoff   75         0.93791    0.34756  62.9%   2.6   50s\r\n",
      " 57207 33179    0.80392   55    -    0.93791    0.35004  62.7%   2.7   55s\r\n",
      " 61605 35248    0.89765   70    -    0.93791    0.35180  62.5%   2.7   60s\r\n",
      " 65319 37011    0.40372   40   11    0.93791    0.35362  62.3%   2.8   65s\r\n",
      " 69035 38775     cutoff   84         0.93791    0.35536  62.1%   2.8   70s\r\n",
      " 72750 40615    0.46951   54    5    0.93791    0.35692  61.9%   2.9   75s\r\n",
      " 75896 42160     cutoff  105         0.93791    0.35828  61.8%   2.9   80s\r\n",
      " 78866 43529     cutoff   64         0.93791    0.35908  61.7%   2.9   85s\r\n",
      " 81517 44766     cutoff   87         0.93791    0.36045  61.6%   3.0   90s\r\n",
      " 84463 46130     cutoff  125         0.93791    0.36165  61.4%   3.0   95s\r\n",
      " 87143 47459    0.91447   84    2    0.93791    0.36261  61.3%   3.0  100s\r\n",
      " 90039 48937     cutoff   88         0.93791    0.36348  61.2%   3.0  105s\r\n",
      " 92722 51147    0.93689   95    4    0.93791    0.36463  61.1%   3.1  110s\r\n",
      " 95203 53163     cutoff  108         0.93791    0.36557  61.0%   3.1  115s\r\n",
      " 97282 54767     cutoff  111         0.93791    0.36628  60.9%   3.1  120s\r\n",
      " 99620 56657    0.88405  110    4    0.93791    0.36704  60.9%   3.2  125s\r\n",
      " 101621 58304     cutoff  112         0.93791    0.36766  60.8%   3.2  130s\r\n",
      " 103865 60002     cutoff   68         0.93791    0.36824  60.7%   3.2  135s\r\n",
      " 106250 61896    0.49493   47    8    0.93791    0.36905  60.7%   3.3  140s\r\n",
      " 107984 63305     cutoff   64         0.93791    0.36958  60.6%   3.3  145s\r\n",
      " 110007 64927     cutoff   79         0.93791    0.37009  60.5%   3.3  150s\r\n",
      " 111163 65892     cutoff   88         0.93791    0.37044  60.5%   3.3  155s\r\n",
      " 112809 67240     cutoff   66         0.93791    0.37080  60.5%   3.4  160s\r\n",
      " 114586 68684     cutoff   91         0.93791    0.37130  60.4%   3.4  165s\r\n",
      " 116575 70217    0.90146   93    3    0.93791    0.37188  60.4%   3.4  170s\r\n",
      " 118543 71872     cutoff  123         0.93791    0.37240  60.3%   3.5  175s\r\n",
      " 120480 73334    0.78092   75    8    0.93791    0.37289  60.2%   3.5  180s\r\n",
      " 121993 74538     cutoff   57         0.93791    0.37324  60.2%   3.5  185s\r\n",
      " 123943 76139     cutoff  104         0.93791    0.37383  60.1%   3.5  190s\r\n",
      " 125648 77475    0.47935   48    9    0.93791    0.37424  60.1%   3.5  195s\r\n",
      " 127154 78659     cutoff   70         0.93791    0.37459  60.1%   3.6  200s\r\n",
      " 128775 79899     cutoff  100         0.93791    0.37515  60.0%   3.6  205s\r\n",
      " 130471 81231    0.74192   79   13    0.93791    0.37554  60.0%   3.6  210s\r\n",
      " 131936 82397    0.74560   62   17    0.93791    0.37592  59.9%   3.6  215s\r\n",
      " 133397 83429    0.56189   50   11    0.93791    0.37620  59.9%   3.6  220s\r\n",
      " 134812 84571     cutoff   79         0.93791    0.37649  59.9%   3.7  225s\r\n",
      " 136329 85711     cutoff  101         0.93791    0.37681  59.8%   3.7  231s\r\n",
      " 137501 86637     cutoff   85         0.93791    0.37710  59.8%   3.7  235s\r\n",
      " 139030 87854    0.47169   46   13    0.93791    0.37757  59.7%   3.7  240s\r\n",
      " 140472 88968     cutoff  124         0.93791    0.37804  59.7%   3.7  245s\r\n",
      " 142116 90238     cutoff   71         0.93791    0.37844  59.7%   3.8  251s\r\n",
      " 142584 90596     cutoff  108         0.93791    0.37852  59.6%   3.8  256s\r\n",
      " 143076 90977    0.69115   75    4    0.93791    0.37865  59.6%   3.8  260s\r\n",
      " 144671 92250    0.48091   46    7    0.93791    0.37908  59.6%   3.8  266s\r\n",
      " 146021 93260     cutoff  110         0.93791    0.37930  59.6%   3.8  270s\r\n",
      " 147711 94669    0.69746   68    2    0.93791    0.37971  59.5%   3.8  275s\r\n",
      "*148731 94429              56       0.9189746    0.37994  58.7%   3.8  279s\r\n",
      " 149204 94804    0.75241   58    2    0.91897    0.38010  58.6%   3.8  281s\r\n",
      " 150271 95651     cutoff  113         0.91897    0.38034  58.6%   3.8  285s\r\n",
      " 151705 96723    0.66872   59    8    0.91897    0.38061  58.6%   3.9  291s\r\n",
      " 152748 97521    0.65612   55   16    0.91897    0.38089  58.6%   3.9  295s\r\n",
      " 153803 98352    0.78423   66   17    0.91897    0.38121  58.5%   3.9  300s\r\n",
      " 155247 99401    0.52458   55    7    0.91897    0.38154  58.5%   3.9  306s\r\n",
      " 156500 100433    0.91195   89    -    0.91897    0.38176  58.5%   3.9  311s\r\n",
      " 157816 101464     cutoff   73         0.91897    0.38205  58.4%   3.9  315s\r\n",
      " 158942 102373     cutoff   88         0.91897    0.38232  58.4%   3.9  320s\r\n",
      " 160066 103144     cutoff  111         0.91897    0.38252  58.4%   3.9  325s\r\n",
      " 161720 104443    0.81567   62   13    0.91897    0.38278  58.3%   4.0  331s\r\n",
      " 162641 105192    0.50370   53    4    0.91897    0.38305  58.3%   4.0  335s\r\n",
      " 163771 106083     cutoff  114         0.91897    0.38322  58.3%   4.0  340s\r\n",
      " 164753 106758     cutoff   70         0.91897    0.38346  58.3%   4.0  345s\r\n",
      "*165523 106406             124       0.9075107    0.38356  57.7%   4.0  346s\r\n",
      " 166159 106918    0.90488   69    2    0.90751    0.38367  57.7%   4.0  350s\r\n",
      " 167139 107697    0.79090   56    5    0.90751    0.38385  57.7%   4.0  355s\r\n",
      " 168431 108659     cutoff   62         0.90751    0.38421  57.7%   4.0  361s\r\n",
      " 169556 109565     cutoff  116         0.90751    0.38444  57.6%   4.0  365s\r\n",
      " 170674 110469     cutoff   91         0.90751    0.38472  57.6%   4.0  370s\r\n",
      " 171879 111343    0.75688   85    2    0.90751    0.38509  57.6%   4.0  376s\r\n",
      " 172483 111822     cutoff  109         0.90751    0.38523  57.6%   4.1  380s\r\n",
      " 173720 112748    0.83162   79   10    0.90751    0.38548  57.5%   4.1  385s\r\n",
      " 174775 113529    0.46764   43    7    0.90751    0.38574  57.5%   4.1  390s\r\n",
      " 175806 114260    0.74032   58    2    0.90751    0.38588  57.5%   4.1  396s\r\n",
      " 177056 115207    0.78646   56    -    0.90751    0.38615  57.4%   4.1  400s\r\n",
      " 178260 116122     cutoff  111         0.90751    0.38636  57.4%   4.1  406s\r\n",
      " 179629 117142     cutoff  125         0.90751    0.38668  57.4%   4.1  411s\r\n",
      " 180318 117583    0.57992   48   10    0.90751    0.38685  57.4%   4.1  415s\r\n",
      " 181219 118309    0.76487   94    3    0.90751    0.38709  57.3%   4.1  420s\r\n",
      " 182299 119165    0.47687   42   11    0.90751    0.38732  57.3%   4.1  425s\r\n",
      " 183474 120040     cutoff   74         0.90751    0.38754  57.3%   4.2  430s\r\n",
      " 184437 120743    0.70789   61   20    0.90751    0.38779  57.3%   4.2  436s\r\n",
      " 185689 121757    0.61201   58   13    0.90751    0.38798  57.2%   4.2  441s\r\n",
      " 186472 122309     cutoff   79         0.90751    0.38812  57.2%   4.2  446s\r\n",
      " 187180 122857    0.82219   67   21    0.90751    0.38823  57.2%   4.2  450s\r\n",
      " 188537 123919    0.61963   60   10    0.90751    0.38858  57.2%   4.2  455s\r\n",
      " 189598 124694     cutoff  103         0.90751    0.38889  57.1%   4.2  460s\r\n",
      " 190818 125647    0.58563   50   11    0.90751    0.38910  57.1%   4.2  466s\r\n",
      " 191798 126402    0.82105   60   16    0.90751    0.38927  57.1%   4.2  471s\r\n",
      " 192581 126961     cutoff  102         0.90751    0.38938  57.1%   4.2  480s\r\n",
      " 193375 127582    0.90254   78   11    0.90751    0.38959  57.1%   4.2  485s\r\n",
      " 194550 128360    0.50535   48    8    0.90751    0.38986  57.0%   4.2  491s\r\n",
      " 195215 128906     cutoff   59         0.90751    0.38992  57.0%   4.3  495s\r\n",
      " 196320 129741    0.80960   49    -    0.90751    0.39010  57.0%   4.3  501s\r\n",
      " 197331 130537     cutoff   75         0.90751    0.39040  57.0%   4.3  506s\r\n",
      " 198114 131102     cutoff   89         0.90751    0.39061  57.0%   4.3  510s\r\n",
      " 199074 131803     cutoff  111         0.90751    0.39079  56.9%   4.3  515s\r\n",
      " 199827 132403     cutoff   78         0.90751    0.39100  56.9%   4.3  520s\r\n",
      " 201002 133317    0.55864   52   11    0.90751    0.39121  56.9%   4.3  526s\r\n",
      " 201978 134096    0.89389   74   13    0.90751    0.39132  56.9%   4.3  530s\r\n",
      " 203132 135014     cutoff  119         0.90751    0.39157  56.9%   4.3  536s\r\n",
      " 203994 135661    0.53613   52    5    0.90751    0.39174  56.8%   4.3  541s\r\n",
      " 204875 136264    0.77470   49    -    0.90751    0.39187  56.8%   4.3  545s\r\n",
      " 206061 137239    0.76515   70   10    0.90751    0.39205  56.8%   4.3  551s\r\n",
      " 206812 137715    0.62613   52    3    0.90751    0.39224  56.8%   4.3  556s\r\n",
      " 207332 138068     cutoff  121         0.90751    0.39231  56.8%   4.4  560s\r\n",
      " 208387 138937    0.58352   55    9    0.90751    0.39250  56.7%   4.4  566s\r\n",
      " 209084 139434    0.67629   61   13    0.90751    0.39262  56.7%   4.4  571s\r\n",
      " 209733 139915    0.53328   50   14    0.90751    0.39272  56.7%   4.4  575s\r\n",
      " 210821 140719    0.89766   67   18    0.90751    0.39283  56.7%   4.4  583s\r\n",
      " 211522 141243    0.57166   57   10    0.90751    0.39296  56.7%   4.4  587s\r\n",
      " 212190 141717     cutoff   97         0.90751    0.39308  56.7%   4.4  590s\r\n",
      " 213306 142609     cutoff   73         0.90751    0.39336  56.7%   4.4  596s\r\n",
      " 214122 143280    0.85003   78   12    0.90751    0.39358  56.6%   4.4  600s\r\n",
      "\r\n",
      "Cutting planes:\r\n",
      "  Gomory: 4\r\n",
      "  MIR: 4\r\n",
      "  Flow cover: 4\r\n",
      "  Lazy constraints: 3149\r\n",
      "\r\n",
      "Explored 214368 nodes (946037 simplex iterations) in 600.11 seconds\r\n",
      "Thread count was 4 (of 4 available processors)\r\n",
      "\r\n",
      "Solution count 10: 0.907511 0.918975 0.937911 ... 1.84036\r\n",
      "\r\n",
      "Time limit reached\r\n",
      "Best objective 9.075107250679e-01, best bound 3.936714984195e-01, gap 56.6207%\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mNot solved to optimality, status: UserLimit\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(best_score, best_k) = (5.592658754072292, 10)\n",
      "I ran the cutting plane algorithm for best sparsity and determined\n",
      "that k=10 had the best error through validation\n"
     ]
    }
   ],
   "source": [
    "X1 = Matrix(train_X) \n",
    "Y1 = Array{Float64}(train_Y)\n",
    "V1 = Matrix(vl_X)\n",
    "V2 = Array{Float64}(vl_Y)\n",
    "best_score = Inf\n",
    "best_k = Inf\n",
    "ks = []\n",
    "As = []\n",
    "Fs = []\n",
    "scores = []\n",
    "\n",
    "for i in [4, 6, 8, 10,12]\n",
    "    push!(ks, i)\n",
    "    betaTS = sparseregression(X1,Y1,i)\n",
    "    \n",
    "    score = evaluate(V1, V2, betaTS)\n",
    "    push!(scores, score)    \n",
    "        if score < best_score\n",
    "        best_score = score\n",
    "        best_k = i\n",
    "        end\n",
    "     A,F= detection_rate(betaTS, betaTrue)  \n",
    "    push!(As, A)\n",
    "    push!(Fs, F)\n",
    "end\n",
    "\n",
    "@show best_score, best_k\n",
    "\n",
    "tablebest = hcat(ks, scores, As, Fs)\n",
    "\n",
    "\n",
    "println(\"I ran the cutting plane algorithm for best sparsity and determined\n",
    "that k=$best_k had the best error through validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×4 Array{Real,2}:\n",
       "  4  0.4  0.0   18.3967 \n",
       "  6  0.6  0.0   13.9161 \n",
       "  8  0.8  0.0    9.36528\n",
       " 10  1.0  0.0    5.59266\n",
       " 12  0.9  0.25   8.20702"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " table = hcat(ks, As, Fs, scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part A)  Ran the cutting plane algorithm provided for \n",
    "sparse linear regression, finding the best sparsity\n",
    "k through validation, noted it was 10. See table above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mabs{T <: Number}(x::AbstractArray{T}) is deprecated, use abs.(x) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1mabs\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::RowVector{Float64,Array{Float64,1}}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1mfit_relaxation!\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::SparseRegression.SparseRegressor, ::Array{Float64,1}, ::Array{Float64,2}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\subha\\Desktop\\ML - HW 2\\SparseRegression.jl:86\u001b[22m\u001b[22m\n",
      " [4] \u001b[1mfit!\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::SparseRegression.SparseRegressor, ::Array{Float64,1}, ::Array{Float64,2}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\subha\\Desktop\\ML - HW 2\\SparseRegression.jl:167\u001b[22m\u001b[22m\n",
      " [5] \u001b[1msparseregression\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Float64,2}, ::Array{Float64,1}, ::Int64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\subha\\Desktop\\ML - HW 2\\SparseRegression.jl:226\u001b[22m\u001b[22m\n",
      " [6] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\loading.jl:515\u001b[22m\u001b[22m\n",
      " [7] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\subha\\.julia\\v0.6\\Compat\\src\\Compat.jl:407\u001b[22m\u001b[22m\n",
      " [8] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\subha\\.julia\\v0.6\\IJulia\\src\\execute_request.jl:154\u001b[22m\u001b[22m\n",
      " [9] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\subha\\.julia\\v0.6\\IJulia\\src\\eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [10] \u001b[1m(::IJulia.##14#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[67], in expression starting on line 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\r\n",
      "Optimize a model with 2 rows, 101 columns and 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [1e-08, 1e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  Bounds range     [1e+00, 1e+00]\r\n",
      "  RHS range        [1e+00, 1e+01]\r\n",
      "Presolve time: 1.49s\r\n",
      "Presolved: 2 rows, 101 columns, 200 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Found heuristic solution: objective 0.6308883\r\n",
      "\r\n",
      "Root relaxation: objective 2.867514e-01, 13 iterations, 0.05 seconds\r\n",
      "\r\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\r\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\r\n",
      "\r\n",
      "     0     0    0.28675    0    2    0.63089    0.28675  54.5%     -    3s\r\n",
      "     0     0    0.28854    0    3    0.63089    0.28854  54.3%     -    5s\r\n",
      "     0     0    0.29144    0    6    0.63089    0.29144  53.8%     -    6s\r\n",
      "     0     0    0.29630    0    6    0.63089    0.29630  53.0%     -    6s\r\n",
      "     0     0    0.29666    0    6    0.63089    0.29666  53.0%     -    6s\r\n",
      "     0     0    0.29685    0    7    0.63089    0.29685  52.9%     -    7s\r\n",
      "     0     0    0.29686    0    7    0.63089    0.29686  52.9%     -    7s\r\n",
      "     0     0    0.29691    0    7    0.63089    0.29691  52.9%     -    7s\r\n",
      "     0     2    0.29691    0    7    0.63089    0.29691  52.9%     -    9s\r\n",
      "   115    99     cutoff   52         0.63089    0.30087  52.3%   1.8   11s\r\n",
      "   743   572    0.44475   24    8    0.63089    0.31057  50.8%   2.1   15s\r\n",
      "   751   577    0.32793   13   10    0.63089    0.31057  50.8%   2.0   20s\r\n",
      "  1826   989    0.45540   32    3    0.63089    0.33047  47.6%   2.4   25s\r\n",
      "  4664  2813     cutoff   50         0.63089    0.34171  45.8%   2.3   32s\r\n",
      "  7951  5117     cutoff   45         0.63089    0.35068  44.4%   2.4   35s\r\n",
      " 14801  9682     cutoff   42         0.63089    0.36310  42.4%   2.8   40s\r\n",
      " 20901 13504     cutoff   33         0.63089    0.37156  41.1%   3.1   45s\r\n",
      " 24926 15932    0.48687   37    7    0.63089    0.37637  40.3%   3.2   51s\r\n",
      " 24937 15939    0.47876   29   13    0.63089    0.37637  40.3%   3.2   70s\r\n",
      " 25666 16227    0.58728   53    4    0.63089    0.37637  40.3%   3.3   75s\r\n",
      " 29999 17657    0.62684   66    3    0.63089    0.39722  37.0%   3.4   80s\r\n",
      " 35277 19296    0.49095   37    8    0.63089    0.41135  34.8%   3.5   85s\r\n",
      " 41272 20956    0.52340   34    2    0.63089    0.42225  33.1%   3.7   90s\r\n",
      " 45987 22002     cutoff   57         0.63089    0.42888  32.0%   3.8   95s\r\n",
      " 50319 22922    0.60414   38   14    0.63089    0.43394  31.2%   3.9  100s\r\n",
      " 53948 23478     cutoff   51         0.63089    0.43814  30.6%   4.0  105s\r\n",
      " 58085 24007     cutoff   48         0.63089    0.44249  29.9%   4.1  110s\r\n",
      " 61740 24400    0.59137   44    -    0.63089    0.44623  29.3%   4.2  115s\r\n",
      " 64515 24613     cutoff   45         0.63089    0.44871  28.9%   4.2  120s\r\n",
      " 67699 24724     cutoff   41         0.63089    0.45235  28.3%   4.3  125s\r\n",
      " 70992 24774    0.59444   53    5    0.63089    0.45467  27.9%   4.4  130s\r\n",
      " 73908 25204     cutoff   45         0.63089    0.45733  27.5%   4.4  135s\r\n",
      " 76716 26219     cutoff   43         0.63089    0.45962  27.1%   4.5  140s\r\n",
      " 79635 27210     cutoff   54         0.63089    0.46174  26.8%   4.6  145s\r\n",
      " 82358 28061    0.50007   38    8    0.63089    0.46437  26.4%   4.6  150s\r\n",
      " 85092 28934     cutoff   49         0.63089    0.46627  26.1%   4.7  155s\r\n",
      " 87612 29646    0.61292   43    5    0.63089    0.46824  25.8%   4.7  161s\r\n",
      " 89586 30156     cutoff   49         0.63089    0.46992  25.5%   4.8  165s\r\n",
      " 92140 30873     cutoff   45         0.63089    0.47184  25.2%   4.8  170s\r\n",
      " 94826 31564     cutoff   44         0.63089    0.47378  24.9%   4.9  175s\r\n",
      " 97507 32267    0.60003   39   11    0.63089    0.47571  24.6%   4.9  180s\r\n",
      " 99695 32767    0.60022   38    9    0.63089    0.47746  24.3%   4.9  185s\r\n",
      " 101959 33313     cutoff   53         0.63089    0.47904  24.1%   5.0  190s\r\n",
      " 104090 33769    0.58355   37   11    0.63089    0.48067  23.8%   5.0  195s\r\n",
      " 106285 34204     cutoff   39         0.63089    0.48200  23.6%   5.1  200s\r\n",
      " 108111 34582     cutoff   52         0.63089    0.48331  23.4%   5.1  205s\r\n",
      " 110440 35058    0.53803   35    9    0.63089    0.48473  23.2%   5.1  210s\r\n",
      " 112364 35371     cutoff   45         0.63089    0.48608  23.0%   5.2  215s\r\n",
      " 114570 35757     cutoff   42         0.63089    0.48717  22.8%   5.2  220s\r\n",
      " 116763 36113    0.61643   39   13    0.63089    0.48871  22.5%   5.2  225s\r\n",
      " 118658 36394    0.55650   39    9    0.63089    0.49006  22.3%   5.3  230s\r\n",
      " 120538 36678    0.58593   41   10    0.63089    0.49115  22.1%   5.3  235s\r\n",
      " 122486 37019    0.57217   40    7    0.63089    0.49211  22.0%   5.3  240s\r\n",
      " 123607 37217     cutoff   47         0.63089    0.49272  21.9%   5.3  248s\r\n",
      " 124027 37243     cutoff   40         0.63089    0.49299  21.9%   5.3  250s\r\n",
      " 125908 37486     cutoff   38         0.63089    0.49414  21.7%   5.4  255s\r\n",
      " 127831 37690    0.56642   39    8    0.63089    0.49534  21.5%   5.4  260s\r\n",
      " 129612 37832     cutoff   39         0.63089    0.49625  21.3%   5.4  265s\r\n",
      " 131554 38041    0.57787   38    6    0.63089    0.49759  21.1%   5.5  270s\r\n",
      " 133087 38182    0.60959   40    2    0.63089    0.49857  21.0%   5.5  275s\r\n",
      " 134726 38351    0.58190   37   10    0.63089    0.49948  20.8%   5.5  280s\r\n",
      " 136666 38499    0.56992   36    8    0.63089    0.50082  20.6%   5.5  285s\r\n",
      " 138616 38699     cutoff   38         0.63089    0.50193  20.4%   5.6  290s\r\n",
      " 140925 38888    0.60168   38    6    0.63089    0.50326  20.2%   5.6  296s\r\n",
      " 142540 39042    0.61048   37    9    0.63089    0.50429  20.1%   5.6  300s\r\n",
      " 144459 39162     cutoff   44         0.63089    0.50536  19.9%   5.6  305s\r\n",
      " 145988 39264    0.58706   42   17    0.63089    0.50624  19.8%   5.7  310s\r\n",
      " 147480 39352    0.56456   37   10    0.63089    0.50707  19.6%   5.7  315s\r\n",
      " 149333 39416    0.61626   42   14    0.63089    0.50801  19.5%   5.7  321s\r\n",
      " 150875 39487     cutoff   37         0.63089    0.50897  19.3%   5.7  326s\r\n",
      " 152485 39537     cutoff   44         0.63089    0.50987  19.2%   5.8  330s\r\n",
      " 154016 39546    0.59868   42   11    0.63089    0.51070  19.1%   5.8  335s\r\n",
      " 155646 39558     cutoff   35         0.63089    0.51161  18.9%   5.8  340s\r\n",
      " 157648 39602     cutoff   49         0.63089    0.51267  18.7%   5.8  345s\r\n",
      " 159265 39721    0.57214   39    9    0.63089    0.51348  18.6%   5.8  350s\r\n",
      " 160863 39772    0.62821   43   13    0.63089    0.51439  18.5%   5.9  355s\r\n",
      " 162386 39767    0.62034   38    7    0.63089    0.51522  18.3%   5.9  360s\r\n",
      " 163582 39813    0.53841   38    4    0.63089    0.51587  18.2%   5.9  365s\r\n",
      " 164678 39818     cutoff   39         0.63089    0.51638  18.1%   5.9  370s\r\n",
      " 166271 39838    0.55510   38   14    0.63089    0.51720  18.0%   5.9  376s\r\n",
      " 167405 39837     cutoff   41         0.63089    0.51789  17.9%   5.9  381s\r\n",
      " 168480 39829     cutoff   39         0.63089    0.51845  17.8%   5.9  386s\r\n",
      " 169262 39825    0.62505   42    9    0.63089    0.51882  17.8%   6.0  390s\r\n",
      " 170808 39831     cutoff   44         0.63089    0.51963  17.6%   6.0  396s\r\n",
      " 172410 39825    0.58828   48    7    0.63089    0.52047  17.5%   6.0  401s\r\n",
      " 173971 39836    0.58923   39   10    0.63089    0.52118  17.4%   6.0  405s\r\n",
      " 175606 39776    0.60762   35   10    0.63089    0.52201  17.3%   6.0  410s\r\n",
      " 176763 39752     cutoff   40         0.63089    0.52260  17.2%   6.0  415s\r\n",
      " 178320 39714     cutoff   44         0.63089    0.52331  17.1%   6.1  420s\r\n",
      " 179824 39619    0.53954   37   14    0.63089    0.52407  16.9%   6.1  426s\r\n",
      " 180986 39566    0.60580   41   13    0.63089    0.52464  16.8%   6.1  430s\r\n",
      " 182837 39472     cutoff   38         0.63089    0.52565  16.7%   6.1  436s\r\n",
      " 184326 39410     cutoff   38         0.63089    0.52646  16.6%   6.1  440s\r\n",
      " 185840 39324    0.58359   36   22    0.63089    0.52726  16.4%   6.1  445s\r\n",
      " 187343 39218     cutoff   43         0.63089    0.52810  16.3%   6.1  450s\r\n",
      " 188841 39135     cutoff   41         0.63089    0.52879  16.2%   6.2  456s\r\n",
      " 189860 39096    0.61786   38    6    0.63089    0.52926  16.1%   6.2  460s\r\n",
      " 191396 38986    0.61513   40    9    0.63089    0.53003  16.0%   6.2  465s\r\n",
      " 192968 38924     cutoff   44         0.63089    0.53076  15.9%   6.2  471s\r\n",
      " 194132 38923    0.56889   37   13    0.63089    0.53122  15.8%   6.2  476s\r\n",
      " 194916 38805     cutoff   40         0.63089    0.53164  15.7%   6.2  480s\r\n",
      " 196494 38695     cutoff   36         0.63089    0.53240  15.6%   6.2  486s\r\n",
      " 197692 38621    0.62138   42    9    0.63089    0.53301  15.5%   6.2  490s\r\n",
      " 199183 38503    0.59692   37    6    0.63089    0.53374  15.4%   6.3  495s\r\n",
      " 200727 38358     cutoff   41         0.63089    0.53444  15.3%   6.3  500s\r\n",
      " 202309 38263     cutoff   40         0.63089    0.53517  15.2%   6.3  505s\r\n",
      " 203809 38115    0.57293   37   13    0.63089    0.53597  15.0%   6.3  510s\r\n",
      " 205354 37952    0.59606   38   12    0.63089    0.53668  14.9%   6.3  515s\r\n",
      " 206897 37816    0.56141   38    8    0.63089    0.53742  14.8%   6.3  520s\r\n",
      " 208398 37660     cutoff   38         0.63089    0.53816  14.7%   6.3  525s\r\n",
      " 209692 37507    0.59844   40   14    0.63089    0.53883  14.6%   6.3  531s\r\n",
      " 210886 37424    0.58087   36   14    0.63089    0.53942  14.5%   6.3  535s\r\n",
      " 212332 37264    0.58593   38    6    0.63089    0.54010  14.4%   6.4  540s\r\n",
      " 213847 37131    0.58798   38    8    0.63089    0.54083  14.3%   6.4  545s\r\n",
      " 215337 36964    0.55483   37   19    0.63089    0.54158  14.2%   6.4  550s\r\n",
      " 216870 36779     cutoff   39         0.63089    0.54229  14.0%   6.4  555s\r\n",
      " 218377 36644     cutoff   53         0.63089    0.54300  13.9%   6.4  560s\r\n",
      " 219942 36522    0.61729   38    8    0.63089    0.54358  13.8%   6.4  565s\r\n",
      " 221417 36354     cutoff   51         0.63089    0.54431  13.7%   6.4  570s\r\n",
      " 222813 36147     cutoff   41         0.63089    0.54497  13.6%   6.4  576s\r\n",
      " 224334 36012    0.57319   39    8    0.63089    0.54563  13.5%   6.4  580s\r\n",
      " 225589 35794     cutoff   42         0.63089    0.54622  13.4%   6.4  585s\r\n",
      " 226994 35603    0.59457   37   16    0.63089    0.54692  13.3%   6.5  590s\r\n",
      " 228418 35396    0.58955   37    8    0.63089    0.54761  13.2%   6.5  595s\r\n",
      " 228765 35342     cutoff   43         0.63089    0.54783  13.2%   6.5  600s\r\n",
      "\r\n",
      "Cutting planes:\r\n",
      "  Gomory: 1\r\n",
      "  MIR: 4\r\n",
      "  Flow cover: 2\r\n",
      "  Lazy constraints: 1244\r\n",
      "\r\n",
      "Explored 229038 nodes (1482327 simplex iterations) in 600.02 seconds\r\n",
      "Thread count was 4 (of 4 available processors)\r\n",
      "\r\n",
      "Solution count 1: 0.630888 \r\n",
      "\r\n",
      "Time limit reached\r\n",
      "Best objective 6.308883395485e-01, best bound 5.479371690998e-01, gap 13.1483%\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mNot solved to optimality, status: UserLimit\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(score, A, F) = (8.369623111091634, 1.0, 0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8.369623111091634, 1.0, 0.0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#noted via validation set that the best k is 10\n",
    "X1 = Matrix(test_X) \n",
    "Y1 = Array{Float64}(test_Y)\n",
    "\n",
    "x1 = Matrix(train_X) \n",
    "y1 = Array{Float64}(train_Y)\n",
    "betaTest = sparseregression(x1,y1,best_k)\n",
    "\n",
    "score = evaluate(X1, Y1, betaTest)\n",
    "A,F= detection_rate(betaTest, betaTrue)\n",
    "\n",
    "@show score, A, F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B ) Compare and contrast this method with your primal approach using the big-M method from Homework 1. If things take too long to run, you can fix M = 1 and k to the best value found by the cutting plane approach. Please make sure that you do at least try other values of M to see how much they affect the solve time and solution quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparseregressionbigM (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using JuMP, Gurobi\n",
    "\n",
    "function sparseregressionbigM(X, y, k, M)\n",
    "    m = Model(solver=GurobiSolver(OutputFlag=0, TimeLimit = 1500))\n",
    "    \n",
    "    p = size(X, 2)\n",
    "\n",
    "    # Variables\n",
    "    @variable(m, t)\n",
    "    @variable(m, β[1:p])\n",
    "    @variable(m, s[1:p], Bin)\n",
    "\n",
    "    # Constraints\n",
    "    @constraint(m, norm(y - X * β) <= t)\n",
    "    @constraint(m, sum(s[j] for j = 1:p) <= k)\n",
    "    @constraint(m, [j=1:p], β[j] <=  M * s[j])\n",
    "    @constraint(m, [j=1:p], β[j] >= -M * s[j])\n",
    "\n",
    "    # Objective\n",
    "    @objective(m, Min, t)\n",
    "\n",
    "    solve(m)\n",
    "\n",
    "    return getvalue(β), getobjectivevalue(m)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = 0.5\n",
      "k = 10\n",
      "Academic license - for non-commercial use only\n",
      "  7.475839 seconds (21.81 k allocations: 2.841 MiB)\n",
      "obj = 10.472474110100396\n",
      "M = 1.0\n",
      "k = 10\n",
      "Academic license - for non-commercial use only\n",
      "  2.811910 seconds (21.81 k allocations: 2.841 MiB)\n",
      "obj = 2.934009834327178\n",
      "M = 2.0\n",
      "k = 10\n",
      "Academic license - for non-commercial use only\n",
      "404.797117 seconds (21.81 k allocations: 2.841 MiB)\n",
      "Academic license - for non-commercial use only\n",
      "(error, A, F) = (5.4228073748299055, 1.0, 0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5.4228073748299055, 1.0, 0.0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDataX = readtable(\"C:/Users/subha/Desktop/ML - HW 2/sparseX2.csv\",header=false);\n",
    "myDataY = readtable(\"C:/Users/subha/Desktop/ML - HW 2/sparseY2.csv\",header=false)[1];\n",
    "myDataB = readtable(\"C:/Users/subha/Desktop/ML - HW 2/sparseB2.csv\",header=false)[1];\n",
    "\n",
    "betaTrue = Array{Float64}(myDataB)\n",
    "\n",
    "using MLDataUtils\n",
    "srand(1)\n",
    "(train_X, train_Y), (test_X, test_Y) = splitobs(shuffleobs((myDataX,myDataY)), at=.5);\n",
    "(train_X, train_Y), (vl_X, vl_Y) = splitobs(shuffleobs((train_X,train_Y)), at=.5);\n",
    "\n",
    "X1 = Matrix(train_X) \n",
    "Y1 = Array{Float64}(train_Y)\n",
    "V1 = Matrix(vl_X)\n",
    "V2 = Array{Float64}(vl_Y)\n",
    "T1 = Matrix(test_X)\n",
    "T2 = Array{Float64}(test_Y)\n",
    "\n",
    "k = 10 # fix k for this run based on best solution from cutting planes. \n",
    "best_error = Inf \n",
    "best_M = 1 #initialize the best M \n",
    "for M = [0.5, 1, 2]\n",
    "    @show M\n",
    "    @show k\n",
    "    @time β, obj = sparseregressionbigM(X1, Y1, k, M)\n",
    "    error = evaluate(V1, V2, β)\n",
    "    if error < best_error\n",
    "        best_error = error \n",
    "        best_M = M\n",
    "    @show obj\n",
    "    end    \n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "β, obj = sparseregressionbigM(X1, Y1, 10, best_M)\n",
    "error = evaluate(T1, T2, β)\n",
    "(A, F) = detection_rate(β, betaTrue)\n",
    "@show error, A, F\n",
    "   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution quality of primal (Big M) takes alot longer compared to cutting planes. Test error goes down as you INCREASE M but it also takes longer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using DataFramesMeta\n",
    "\n",
    "myDataX = readtable(\"C:/Users/subha/Desktop/ML - HW 2/sparseX2.csv\",header=false);\n",
    "myDataY = readtable(\"C:/Users/subha/Desktop/ML - HW 2/sparseY2.csv\",header=false)[1];\n",
    "myDataB = readtable(\"C:/Users/subha/Desktop/ML - HW 2/sparseB2.csv\",header=false)[1];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using DataFrames\n",
    "# X = Matrix(myDataX) \n",
    "# y = Array{Float64}(myDataY)\n",
    "# w = Array{Float64}(myDataB)\n",
    "# M = 1\n",
    "\n",
    "# for k = [5,10,15,20]\n",
    "#     @show M\n",
    "#     @show k\n",
    "#     @time β, obj = sparseregressionbigM(X, y, k, M)\n",
    "#     @show detection_rate(β, w)\n",
    "#     @show obj\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution quality of primal (Big M) on the whole data set is not very accurate either. It takes quite a lot of time to run the code as well as the fact that the detection rates of the accuracy and the false positive rates are too varied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C)  Compare and contrast the cutting plane method with ridge and lasso regression (you can reuse your code from the first part of Homework 1). In particular you should compare the accuracy and false positive rates and the errors of each method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lasso_reg (generic function with 1 method)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function lasso_reg(X, y, ρ)\n",
    "    m = Model(solver=GurobiSolver(OutputFlag=0))\n",
    "\n",
    "    p = size(X, 2)\n",
    "\n",
    "    # Variables\n",
    "    @variable(m, t)\n",
    "    @variable(m, θ)\n",
    "    @variable(m, β[1:p])\n",
    "    @variable(m, z[1:p])\n",
    "\n",
    "    # Constraints\n",
    "    @constraint(m, norm(y - X * β) <= t)\n",
    "    @constraint(m, sum(z[j] for j = 1:p) <= θ)\n",
    "    @constraint(m, [j=1:p], z[j] >=  β[j])\n",
    "    @constraint(m, [j=1:p], z[j] >= -β[j])\n",
    "\n",
    "    # Objective\n",
    "    @objective(m, Min, t + ρ * θ)\n",
    "\n",
    "    solve(m)\n",
    "\n",
    "    return getvalue(β)\n",
    "end\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Academic license - for non-commercial use only\r\n",
      "best_rho = 1.0\n",
      "Academic license - for non-commercial use only\r\n",
      "(A, F, score) = (1.0, 0.9, 9.915520376579174)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9, 9.915520376579174)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST OF LASSO #\n",
    "srand(1)\n",
    "(train_X, train_Y), (test_X, test_Y) = splitobs(shuffleobs((myDataX,myDataY)), at=.5)\n",
    "(train_X, train_Y), (vl_X, vl_Y) = splitobs(shuffleobs((train_X,train_Y)), at=.5)\n",
    "X1tr = Matrix(train_X) \n",
    "Y1tr = Array{Float64}(train_Y)\n",
    "X1va = Matrix(vl_X)\n",
    "Y1va = Array{Float64}(vl_Y)\n",
    "X1te = Matrix(test_X) \n",
    "Y1te = Array{Float64}(test_Y)\n",
    "best_rho = Inf\n",
    "best_score = Inf\n",
    "for rho in [.01, .1, .5, 1, 2]\n",
    "    β = lasso_reg(X1tr, Y1tr,rho)\n",
    "    score = evaluate(X1va,Y1va,β)\n",
    "    if score < best_score\n",
    "        best_score = score\n",
    "        best_rho = rho\n",
    "    end\n",
    "    w = Array{Float64}(myDataB)\n",
    "    A,F= detection_rate(β, w)\n",
    "end\n",
    "@show best_rho\n",
    "\n",
    "betatest = lasso_reg(X1tr, Y1tr,best_rho)\n",
    "score = evaluate(X1te, Y1te, betatest)\n",
    "A,F= detection_rate(betatest, w)\n",
    "@show A, F, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ridge_reg (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ridge_reg(X, y, ρ)\n",
    "    m = Model(solver=GurobiSolver(OutputFlag=0))\n",
    "\n",
    "    p = size(X, 2)\n",
    "\n",
    "    # Variables\n",
    "    @variable(m, t)\n",
    "    @variable(m, θ)\n",
    "    @variable(m, β[1:p])\n",
    "\n",
    "    # Constraints\n",
    "    @constraint(m, norm(y - X * β) <= t)\n",
    "    @constraint(m, norm(β) <= θ)\n",
    "\n",
    "    # Objective\n",
    "    @objective(m, Min, t + ρ * θ)\n",
    "\n",
    "    solve(m)\n",
    "\n",
    "    return getvalue(β)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "best_rho = 0.01\n",
      "Academic license - for non-commercial use only\n",
      "(A, F, score) = (1.0, 0.9, 23.872598262708497)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9, 23.872598262708497)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST OF Ridge #\n",
    "srand(1)\n",
    "(train_X, train_Y), (test_X, test_Y) = splitobs(shuffleobs((myDataX,myDataY)), at=.5)\n",
    "(train_X, train_Y), (vl_X, vl_Y) = splitobs(shuffleobs((train_X,train_Y)), at=.5)\n",
    "X1tr = Matrix(train_X) \n",
    "Y1tr = Array{Float64}(train_Y)\n",
    "X1va = Matrix(vl_X)\n",
    "Y1va = Array{Float64}(vl_Y)\n",
    "X1te = Matrix(test_X) \n",
    "Y1te = Array{Float64}(test_Y)\n",
    "best_rho = Inf\n",
    "best_score = Inf\n",
    "for rho in [.01, .1, .5, 1, 2]\n",
    "    β = ridge_reg(X1tr, Y1tr,rho)\n",
    "    score = evaluate(X1va,Y1va,β)\n",
    "    if score < best_score\n",
    "        best_score = score\n",
    "        best_rho = rho\n",
    "    end\n",
    "    w = Array{Float64}(myDataB)\n",
    "    A,F= detection_rate(β, w)\n",
    "end\n",
    "@show best_rho\n",
    "\n",
    "betatest = ridge_reg(X1tr, Y1tr,best_rho)\n",
    "score = evaluate(X1te, Y1te, betatest)\n",
    "A,F= detection_rate(betatest, w)\n",
    "@show A, F, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lasso and ridge regressions take a short amount of time, but are yielding high false positive rates. While they have a 100% accuracy rate, they are not very useful because these methods are not good at identifying features which are false positives. The score from the evaluate  functions are bigger for ridge and lasso. The order of the best methods are the sparse regression (cutting planes), lasso, and ridge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element Array{Float64,1}:\n",
       " -3.44753 \n",
       "  1.67705 \n",
       " -5.21783 \n",
       "  8.5104  \n",
       "  2.23237 \n",
       " -0.713251\n",
       " -0.366368\n",
       "  0.826948\n",
       "  1.22937 \n",
       "  3.45285 \n",
       "  2.34286 \n",
       "  8.06128 \n",
       "  2.71377 \n",
       "  ⋮       \n",
       "  4.66784 \n",
       "  0.469463\n",
       " -4.05879 \n",
       "  0.403874\n",
       " -1.06833 \n",
       "  1.30128 \n",
       "  8.82361 \n",
       " -0.346036\n",
       "  0.673077\n",
       " -4.52402 \n",
       " -3.60963 \n",
       "  0.92946 "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X1te = Matrix(test_X) \n",
    "Y1te = Array{Float64,1}(test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D ) Try running the regression on only the first 100 points in the dataset, then the first 90 points only, and so on for 80, 70, and so on down to 20. What do you observe?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mabs{T <: Number}(x::AbstractArray{T}) is deprecated, use abs.(x) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1mabs\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::RowVector{Float64,Array{Float64,1}}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1mfit_relaxation!\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::SparseRegression.SparseRegressor, ::Array{Float64,1}, ::Array{Float64,2}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\subha\\Desktop\\ML - HW 2\\SparseRegression.jl:86\u001b[22m\u001b[22m\n",
      " [4] \u001b[1mfit!\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::SparseRegression.SparseRegressor, ::Array{Float64,1}, ::Array{Float64,2}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\subha\\Desktop\\ML - HW 2\\SparseRegression.jl:167\u001b[22m\u001b[22m\n",
      " [5] \u001b[1msparseregression\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\subha\\Desktop\\ML - HW 2\\SparseRegression.jl:226\u001b[22m\u001b[22m [inlined]\n",
      " [6] \u001b[1mmacro expansion\u001b[22m\u001b[22m at \u001b[1m.\\In[48]:16\u001b[22m\u001b[22m [inlined]\n",
      " [7] \u001b[1manonymous\u001b[22m\u001b[22m at \u001b[1m.\\<missing>:?\u001b[22m\u001b[22m\n",
      " [8] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\loading.jl:515\u001b[22m\u001b[22m\n",
      " [9] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\subha\\.julia\\v0.6\\Compat\\src\\Compat.jl:407\u001b[22m\u001b[22m\n",
      " [10] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\subha\\.julia\\v0.6\\IJulia\\src\\execute_request.jl:154\u001b[22m\u001b[22m\n",
      " [11] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\subha\\.julia\\v0.6\\IJulia\\src\\eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [12] \u001b[1m(::IJulia.##14#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[48], in expression starting on line 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\r\n",
      "Optimize a model with 2 rows, 101 columns and 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [5e-08, 1e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  Bounds range     [1e+00, 1e+00]\r\n",
      "  RHS range        [9e-01, 1e+01]\r\n",
      "Presolve time: 0.00s\r\n",
      "Presolved: 2 rows, 101 columns, 200 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Found heuristic solution: objective 0.5235982\r\n",
      "\r\n",
      "Root relaxation: objective 3.660638e-01, 12 iterations, 0.00 seconds\r\n",
      "\r\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\r\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\r\n",
      "\r\n",
      "     0     0    0.36606    0    2    0.52360    0.36606  30.1%     -    0s\r\n",
      "     0     0    0.36728    0    4    0.52360    0.36728  29.9%     -    0s\r\n",
      "     0     0    0.36736    0    4    0.52360    0.36736  29.8%     -    0s\r\n",
      "     0     0    0.36868    0    5    0.52360    0.36868  29.6%     -    0s\r\n",
      "     0     0    0.36885    0    6    0.52360    0.36885  29.6%     -    0s\r\n",
      "     0     0    0.36947    0    6    0.52360    0.36947  29.4%     -    0s\r\n",
      "     0     0    0.36952    0    6    0.52360    0.36952  29.4%     -    0s\r\n",
      "     0     0    0.36959    0    6    0.52360    0.36959  29.4%     -    0s\r\n",
      "     0     2    0.36959    0    6    0.52360    0.36959  29.4%     -    0s\r\n",
      "  8698  4779    0.47626   31    4    0.52360    0.39497  24.6%   2.2    5s\r\n",
      " 17974  8413     cutoff   30         0.52360    0.40738  22.2%   2.7   10s\r\n",
      " 24145  9126    0.49364   31    3    0.52360    0.41917  19.9%   3.2   15s\r\n",
      " 28763  8852     cutoff   30         0.52360    0.43156  17.6%   3.6   20s\r\n",
      " 32953  8071     cutoff   30         0.52360    0.44485  15.0%   3.9   25s\r\n",
      " 36853  7091     cutoff   32         0.52360    0.45837  12.5%   4.1   30s\r\n",
      " 41092  5999     cutoff   32         0.52360    0.47017  10.2%   4.3   35s\r\n",
      " 45498  4351     cutoff   28         0.52360    0.48382  7.60%   4.3   40s\r\n",
      " 50168  1649     cutoff   33         0.52360    0.50449  3.65%   4.3   45s\r\n",
      "\r\n",
      "Cutting planes:\r\n",
      "  Gomory: 4\r\n",
      "  Cover: 6\r\n",
      "  MIR: 8\r\n",
      "  Flow cover: 39\r\n",
      "  Lazy constraints: 743\r\n",
      "\r\n",
      "Explored 51941 nodes (221009 simplex iterations) in 46.01 seconds\r\n",
      "Thread count was 4 (of 4 available processors)\r\n",
      "\r\n",
      "Solution count 1: 0.523598 \r\n",
      "\r\n",
      "Optimal solution found (tolerance 1.00e-02)\r\n",
      "Best objective 5.235981504382e-01, best bound 5.192836627258e-01, gap 0.8240%\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Optimize a model with 2 rows, 101 columns and 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [1e-05, 1e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  Bounds range     [1e+00, 1e+00]\r\n",
      "  RHS range        [1e+00, 1e+01]\r\n",
      "Presolve time: 0.00s\r\n",
      "Presolved: 2 rows, 101 columns, 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Found heuristic solution: objective 0.5416697\r\n",
      "\r\n",
      "Root relaxation: objective 3.750187e-01, 14 iterations, 0.00 seconds\r\n",
      "\r\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\r\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\r\n",
      "\r\n",
      "     0     0    0.37502    0    2    0.54167    0.37502  30.8%     -    0s\r\n",
      "     0     0    0.37704    0    4    0.54167    0.37704  30.4%     -    0s\r\n",
      "     0     0    0.37704    0    4    0.54167    0.37704  30.4%     -    0s\r\n",
      "     0     0    0.37924    0    5    0.54167    0.37924  30.0%     -    0s\r\n",
      "     0     0    0.37966    0    5    0.54167    0.37966  29.9%     -    0s\r\n",
      "     0     0    0.37967    0    5    0.54167    0.37967  29.9%     -    0s\r\n",
      "     0     2    0.37992    0    6    0.54167    0.37992  29.9%     -    0s\r\n",
      "  9697  2273     cutoff   29         0.54167    0.45216  16.5%   3.3    5s\r\n",
      "\r\n",
      "Cutting planes:\r\n",
      "  Gomory: 2\r\n",
      "  Cover: 5\r\n",
      "  MIR: 4\r\n",
      "  Flow cover: 28\r\n",
      "  Lazy constraints: 344\r\n",
      "\r\n",
      "Explored 16025 nodes (61358 simplex iterations) in 7.86 seconds\r\n",
      "Thread count was 4 (of 4 available processors)\r\n",
      "\r\n",
      "Solution count 1: 0.54167 \r\n",
      "\r\n",
      "Optimal solution found (tolerance 1.00e-02)\r\n",
      "Best objective 5.416697415044e-01, best bound 5.390262774330e-01, gap 0.4880%\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Optimize a model with 2 rows, 101 columns and 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [2e-05, 1e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  Bounds range     [1e+00, 1e+00]\r\n",
      "  RHS range        [1e+00, 1e+01]\r\n",
      "Presolve time: 0.00s\r\n",
      "Presolved: 2 rows, 101 columns, 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Found heuristic solution: objective 0.5661185\r\n",
      "\r\n",
      "Root relaxation: objective 4.281957e-01, 9 iterations, 0.00 seconds\r\n",
      "\r\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\r\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\r\n",
      "\r\n",
      "     0     0    0.42820    0    2    0.56612    0.42820  24.4%     -    0s\r\n",
      "     0     0    0.42988    0    4    0.56612    0.42988  24.1%     -    0s\r\n",
      "     0     0    0.43004    0    4    0.56612    0.43004  24.0%     -    0s\r\n",
      "     0     0    0.43108    0    5    0.56612    0.43108  23.9%     -    0s\r\n",
      "     0     0    0.43110    0    5    0.56612    0.43110  23.8%     -    0s\r\n",
      "     0     0    0.43192    0    4    0.56612    0.43192  23.7%     -    0s\r\n",
      "     0     0    0.43207    0    4    0.56612    0.43207  23.7%     -    0s\r\n",
      "     0     0    0.43218    0    5    0.56612    0.43218  23.7%     -    0s\r\n",
      "     0     2    0.43242    0    6    0.56612    0.43242  23.6%     -    0s\r\n",
      " 12851  1565    0.54469   22   15    0.56612    0.52383  7.47%   4.3    5s\r\n",
      "\r\n",
      "Cutting planes:\r\n",
      "  Gomory: 1\r\n",
      "  Cover: 1\r\n",
      "  MIR: 3\r\n",
      "  Flow cover: 4\r\n",
      "  Lazy constraints: 182\r\n",
      "\r\n",
      "Explored 16543 nodes (73919 simplex iterations) in 6.56 seconds\r\n",
      "Thread count was 4 (of 4 available processors)\r\n",
      "\r\n",
      "Solution count 1: 0.566119 \r\n",
      "\r\n",
      "Optimal solution found (tolerance 1.00e-02)\r\n",
      "Best objective 5.661185478474e-01, best bound 5.614641115041e-01, gap 0.8222%\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Optimize a model with 2 rows, 101 columns and 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [2e-05, 1e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  Bounds range     [1e+00, 1e+00]\r\n",
      "  RHS range        [1e+00, 1e+01]\r\n",
      "Presolve time: 0.00s\r\n",
      "Presolved: 2 rows, 101 columns, 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Found heuristic solution: objective 0.5837850\r\n",
      "\r\n",
      "Root relaxation: objective 4.735218e-01, 12 iterations, 0.00 seconds\r\n",
      "\r\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\r\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\r\n",
      "\r\n",
      "     0     0    0.47352    0    2    0.58379    0.47352  18.9%     -    0s\r\n",
      "     0     0    0.48079    0    5    0.58379    0.48079  17.6%     -    0s\r\n",
      "     0     0    0.48105    0    6    0.58379    0.48105  17.6%     -    0s\r\n",
      "     0     2    0.48105    0    6    0.58379    0.48105  17.6%     -    0s\r\n",
      "\r\n",
      "Cutting planes:\r\n",
      "  Gomory: 3\r\n",
      "  Cover: 3\r\n",
      "  MIR: 8\r\n",
      "  Flow cover: 10\r\n",
      "  Inf proof: 1\r\n",
      "  Lazy constraints: 111\r\n",
      "\r\n",
      "Explored 9490 nodes (34810 simplex iterations) in 2.90 seconds\r\n",
      "Thread count was 4 (of 4 available processors)\r\n",
      "\r\n",
      "Solution count 1: 0.583785 \r\n",
      "\r\n",
      "Optimal solution found (tolerance 1.00e-02)\r\n",
      "Best objective 5.837850026863e-01, best bound 5.780265019298e-01, gap 0.9864%\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Optimize a model with 2 rows, 101 columns and 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [8e-06, 1e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  Bounds range     [1e+00, 1e+00]\r\n",
      "  RHS range        [1e+00, 1e+01]\r\n",
      "Presolve time: 0.00s\r\n",
      "Presolved: 2 rows, 101 columns, 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Found heuristic solution: objective 0.5962566\r\n",
      "\r\n",
      "Root relaxation: objective 4.759826e-01, 11 iterations, 0.00 seconds\r\n",
      "\r\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\r\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\r\n",
      "\r\n",
      "     0     0    0.47598    0    2    0.59626    0.47598  20.2%     -    0s\r\n",
      "     0     0    0.48675    0    4    0.59626    0.48675  18.4%     -    0s\r\n",
      "     0     0    0.48958    0    4    0.59626    0.48958  17.9%     -    0s\r\n",
      "     0     0    0.49052    0    5    0.59626    0.49052  17.7%     -    0s\r\n",
      "     0     0    0.49074    0    5    0.59626    0.49074  17.7%     -    0s\r\n",
      "     0     0    0.49079    0    6    0.59626    0.49079  17.7%     -    0s\r\n",
      "     0     0    0.49178    0    6    0.59626    0.49178  17.5%     -    0s\r\n",
      "     0     2    0.49178    0    6    0.59626    0.49178  17.5%     -    0s\r\n",
      "\r\n",
      "Cutting planes:\r\n",
      "  Gomory: 8\r\n",
      "  MIR: 17\r\n",
      "  Flow cover: 9\r\n",
      "  Lazy constraints: 222\r\n",
      "\r\n",
      "Explored 17079 nodes (62516 simplex iterations) in 4.45 seconds\r\n",
      "Thread count was 4 (of 4 available processors)\r\n",
      "\r\n",
      "Solution count 1: 0.596257 \r\n",
      "\r\n",
      "Optimal solution found (tolerance 1.00e-02)\r\n",
      "Best objective 5.962566235352e-01, best bound 5.922762809497e-01, gap 0.6676%\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Optimize a model with 2 rows, 101 columns and 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [6e-10, 1e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  Bounds range     [1e+00, 1e+00]\r\n",
      "  RHS range        [1e+00, 1e+01]\r\n",
      "Presolve time: 0.00s\r\n",
      "Presolved: 2 rows, 101 columns, 200 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "\r\n",
      "Root relaxation: objective 0.000000e+00, 7 iterations, 0.00 seconds\r\n",
      "\r\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\r\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\r\n",
      "\r\n",
      "     0     0    0.00000    0    2          -    0.00000      -     -    0s\r\n",
      "H    0     0                       0.9540449    0.00000   100%     -    0s\r\n",
      "     0     0    0.00000    0    2    0.95404    0.00000   100%     -    0s\r\n",
      "     0     0    0.00000    0    3    0.95404    0.00000   100%     -    0s\r\n",
      "H    0     0                       0.6017015    0.00000   100%     -    0s\r\n",
      "     0     2    0.25860    0    3    0.60170    0.25860  57.0%     -    0s\r\n",
      " 13893  6487    0.50221   23   11    0.60170    0.39634  34.1%   4.3    5s\r\n",
      " 22717  8712    0.59753   34    3    0.60170    0.43342  28.0%   5.0   10s\r\n",
      " 29653  9807    0.54579   28    6    0.60170    0.45632  24.2%   5.3   15s\r\n",
      " 36889 10392    0.57555   30   16    0.60170    0.47714  20.7%   5.6   20s\r\n",
      " 43387 10493    0.59394   26    8    0.60170    0.49320  18.0%   5.7   25s\r\n",
      " 50506 10334     cutoff   25         0.60170    0.50818  15.5%   5.9   30s\r\n",
      " 56342  9755     cutoff   31         0.60170    0.51987  13.6%   6.0   35s\r\n",
      " 61964  8980     cutoff   27         0.60170    0.53123  11.7%   6.1   40s\r\n",
      " 67675  7877     cutoff   28         0.60170    0.54210  9.90%   6.1   45s\r\n",
      " 73883  6034     cutoff   31         0.60170    0.55553  7.67%   6.2   50s\r\n",
      " 79725  3721     cutoff   25         0.60170    0.56909  5.42%   6.2   55s\r\n",
      "\r\n",
      "Cutting planes:\r\n",
      "  Gomory: 1\r\n",
      "  Cover: 1\r\n",
      "  MIR: 1\r\n",
      "  Flow cover: 1\r\n",
      "  Lazy constraints: 586\r\n",
      "\r\n",
      "Explored 85020 nodes (520471 simplex iterations) in 58.97 seconds\r\n",
      "Thread count was 4 (of 4 available processors)\r\n",
      "\r\n",
      "Solution count 2: 0.601701 0.954045 \r\n",
      "\r\n",
      "Optimal solution found (tolerance 1.00e-02)\r\n",
      "Best objective 6.017014612899e-01, best bound 5.962421067046e-01, gap 0.9073%\r\n",
      "Academic license - for non-commercial use only\r\n",
      "Optimize a model with 2 rows, 101 columns and 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [1e-06, 1e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  Bounds range     [1e+00, 1e+00]\r\n",
      "  RHS range        [1e+00, 1e+01]\r\n",
      "Presolve time: 0.00s\r\n",
      "Presolved: 2 rows, 101 columns, 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "\r\n",
      "Root relaxation: objective 1.802983e-01, 9 iterations, 0.00 seconds\r\n",
      "\r\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\r\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\r\n",
      "\r\n",
      "     0     0    0.18030    0    2          -    0.18030      -     -    0s\r\n",
      "H    0     0                       1.6840836    0.18030  89.3%     -    0s\r\n",
      "H    0     0                       1.5200755    0.18030  88.1%     -    0s\r\n",
      "H    0     0                       1.1135308    0.18030  83.8%     -    0s\r\n",
      "     0     0    0.19320    0    4    1.11353    0.19320  82.6%     -    0s\r\n",
      "     0     0    0.19369    0    5    1.11353    0.19369  82.6%     -    0s\r\n",
      "     0     0    0.19559    0    4    1.11353    0.19559  82.4%     -    0s\r\n",
      "     0     0    0.20193    0    7    1.11353    0.20193  81.9%     -    0s\r\n",
      "     0     0    0.20247    0    6    1.11353    0.20247  81.8%     -    0s\r\n",
      "     0     0    0.20399    0    6    1.11353    0.20399  81.7%     -    0s\r\n",
      "     0     0    0.20479    0    8    1.11353    0.20479  81.6%     -    0s\r\n",
      "     0     0    0.20498    0    8    1.11353    0.20498  81.6%     -    0s\r\n",
      "     0     0    0.20688    0    7    1.11353    0.20688  81.4%     -    0s\r\n",
      "     0     2    0.21459    0    6    1.11353    0.21459  80.7%     -    0s\r\n",
      "*  353   240              26       0.8981726    0.26422  70.6%   2.1    0s\r\n",
      "* 5000  3123              31       0.7999122    0.32041  59.9%   2.5    0s\r\n",
      " 17809 12687     cutoff   46         0.79991    0.36083  54.9%   3.4    5s\r\n",
      " 20332 14432    0.65851   73   14    0.79991    0.36685  54.1%   3.5   10s\r\n",
      " 20348 14443    0.51351   34   14    0.79991    0.36685  54.1%   3.5   19s\r\n",
      " 20359 14455    0.38385   29   14    0.79991    0.36685  54.1%   3.5   20s\r\n",
      "*20754 13880              45       0.7649923    0.36832  51.9%   3.6   20s\r\n",
      " 25346 15756     cutoff   75         0.76499    0.40791  46.7%   3.7   25s\r\n",
      " 31882 18374     cutoff   69         0.76499    0.42366  44.6%   3.8   30s\r\n",
      " 37104 20452    0.53822   36    2    0.76499    0.43352  43.3%   3.9   35s\r\n",
      "*37110 19603              37       0.7559873    0.43352  42.7%   3.9   35s\r\n",
      " 40780 20939    0.56798   44   11    0.75599    0.43907  41.9%   4.0   40s\r\n",
      " 44796 22321    0.65456   52   11    0.75599    0.44475  41.2%   4.1   45s\r\n",
      " 48761 23690    0.64492   77    4    0.75599    0.44944  40.5%   4.2   50s\r\n",
      " 51958 24728     cutoff   43         0.75599    0.45330  40.0%   4.3   55s\r\n",
      " 55111 25813     cutoff   94         0.75599    0.45703  39.5%   4.4   60s\r\n",
      " 58150 26775     cutoff   56         0.75599    0.46039  39.1%   4.5   65s\r\n",
      " 60740 27929    0.62074   45   13    0.75599    0.46353  38.7%   4.5   70s\r\n",
      " 63008 29382     cutoff   75         0.75599    0.46573  38.4%   4.6   75s\r\n",
      " 65216 30753    0.73538   57    6    0.75599    0.46783  38.1%   4.6   80s\r\n",
      " 67315 32074     cutoff   63         0.75599    0.46989  37.8%   4.7   85s\r\n",
      " 68951 33123    0.53572   37    9    0.75599    0.47128  37.7%   4.8   90s\r\n",
      " 71347 34533     cutoff   57         0.75599    0.47376  37.3%   4.8   95s\r\n",
      " 73002 35550    0.70484   44   16    0.75599    0.47512  37.2%   4.8  100s\r\n",
      " 75128 36863     cutoff   54         0.75599    0.47727  36.9%   4.9  105s\r\n",
      " 77113 38028    0.69658   54    4    0.75599    0.47877  36.7%   4.9  110s\r\n",
      " 78759 38946     cutoff   90         0.75599    0.48016  36.5%   5.0  115s\r\n",
      " 80700 40068     cutoff   48         0.75599    0.48134  36.3%   5.0  120s\r\n",
      " 82582 41195     cutoff   56         0.75599    0.48258  36.2%   5.0  125s\r\n",
      " 84225 41997     cutoff   55         0.75599    0.48390  36.0%   5.1  130s\r\n",
      " 86123 43113    0.59138   45    9    0.75599    0.48544  35.8%   5.1  135s\r\n",
      " 87718 44001    0.66601   41    2    0.75599    0.48681  35.6%   5.1  140s\r\n",
      " 89434 44940     cutoff   62         0.75599    0.48789  35.5%   5.1  145s\r\n",
      " 89770 45151    0.64352   42   14    0.75599    0.48824  35.4%   5.2  150s\r\n",
      " 91416 46059     cutoff   53         0.75599    0.48929  35.3%   5.2  155s\r\n",
      " 92624 46699    0.63432   44   15    0.75599    0.49029  35.1%   5.2  160s\r\n",
      " 94193 47570     cutoff   42         0.75599    0.49138  35.0%   5.3  166s\r\n",
      " 95388 48250     cutoff   51         0.75599    0.49244  34.9%   5.3  171s\r\n",
      " 96448 48880     cutoff   47         0.75599    0.49300  34.8%   5.3  175s\r\n",
      " 97782 49606     cutoff   76         0.75599    0.49410  34.6%   5.3  180s\r\n",
      " 99259 50389     cutoff   68         0.75599    0.49493  34.5%   5.4  185s\r\n",
      " 100740 51197     cutoff   71         0.75599    0.49598  34.4%   5.4  190s\r\n",
      " 102260 52020     cutoff   42         0.75599    0.49697  34.3%   5.4  196s\r\n",
      " 103339 52665     cutoff   48         0.75599    0.49765  34.2%   5.4  200s\r\n",
      " 104650 53275     cutoff   67         0.75599    0.49840  34.1%   5.4  205s\r\n",
      " 106073 53968     cutoff   51         0.75599    0.49929  34.0%   5.5  210s\r\n",
      " 107073 54440     cutoff   51         0.75599    0.49998  33.9%   5.5  215s\r\n",
      " 108456 55174     cutoff   71         0.75599    0.50102  33.7%   5.5  220s\r\n",
      " 109899 55880    0.75365   68    2    0.75599    0.50193  33.6%   5.5  226s\r\n",
      " 111060 56550     cutoff   67         0.75599    0.50262  33.5%   5.6  230s\r\n",
      "*111103 51088              39       0.7292226    0.50262  31.1%   5.6  230s\r\n",
      " 111893 51428    0.71793   45   18    0.72922    0.50311  31.0%   5.6  235s\r\n",
      " 112976 51985    0.69442   46    9    0.72922    0.50367  30.9%   5.6  240s\r\n",
      " 113606 52305     cutoff   50         0.72922    0.50418  30.9%   5.6  245s\r\n",
      " 114750 52838     cutoff   49         0.72922    0.50483  30.8%   5.6  250s\r\n",
      " 115827 53287    0.65420   44    8    0.72922    0.50557  30.7%   5.7  255s\r\n",
      " 116988 53851     cutoff   82         0.72922    0.50657  30.5%   5.7  261s\r\n",
      " 117697 54147     cutoff   46         0.72922    0.50724  30.4%   5.7  265s\r\n",
      " 118581 54540     cutoff   48         0.72922    0.50801  30.3%   5.7  270s\r\n",
      " 119721 55040     cutoff   66         0.72922    0.50862  30.3%   5.7  276s\r\n",
      " 120656 55432    0.72801   59   19    0.72922    0.50919  30.2%   5.7  281s\r\n",
      " 121348 55681     cutoff   53         0.72922    0.50982  30.1%   5.8  285s\r\n",
      " 122360 56137     cutoff   42         0.72922    0.51046  30.0%   5.8  292s\r\n",
      " 122980 56431    0.63998   38   23    0.72922    0.51094  29.9%   5.8  296s\r\n",
      " 123659 56676    0.68909   45   11    0.72922    0.51135  29.9%   5.8  300s\r\n",
      " 124693 57081    0.69271   47    6    0.72922    0.51215  29.8%   5.8  305s\r\n",
      " 125716 57486     cutoff   66         0.72922    0.51271  29.7%   5.9  311s\r\n",
      " 126483 57835    0.70404   46    2    0.72922    0.51331  29.6%   5.9  315s\r\n",
      " 127485 58185    0.72217   50    2    0.72922    0.51403  29.5%   5.9  320s\r\n",
      " 128482 58613    0.72411   53    8    0.72922    0.51467  29.4%   5.9  326s\r\n",
      " 129224 58879    0.72511   49   11    0.72922    0.51512  29.4%   5.9  330s\r\n",
      " 130465 59413    0.66862   43    6    0.72922    0.51576  29.3%   5.9  335s\r\n",
      " 131507 59848     cutoff   53         0.72922    0.51663  29.2%   6.0  342s\r\n",
      " 132286 60227     cutoff   69         0.72922    0.51708  29.1%   6.0  345s\r\n",
      " 133051 60528    0.61666   45   11    0.72922    0.51775  29.0%   6.0  350s\r\n",
      " 134112 60907     cutoff   51         0.72922    0.51845  28.9%   6.0  355s\r\n",
      " 135327 61414    0.67941   46    7    0.72922    0.51913  28.8%   6.0  361s\r\n",
      " 135957 61673    0.70500   44   14    0.72922    0.51955  28.8%   6.0  365s\r\n",
      " 137106 62114    0.70910   54   17    0.72922    0.52033  28.6%   6.1  371s\r\n",
      " 137820 62365     cutoff   41         0.72922    0.52078  28.6%   6.1  375s\r\n",
      " 138928 62744     cutoff   50         0.72922    0.52151  28.5%   6.1  381s\r\n",
      " 139794 63079    0.67624   43    5    0.72922    0.52204  28.4%   6.1  385s\r\n",
      " 140515 63369    0.69948   58   12    0.72922    0.52241  28.4%   6.1  390s\r\n",
      " 141125 63610    0.66457   42   15    0.72922    0.52283  28.3%   6.1  398s\r\n",
      " 141391 63696    0.72170   44    9    0.72922    0.52309  28.3%   6.1  401s\r\n",
      " 142041 63925    0.64921   43   16    0.72922    0.52341  28.2%   6.1  406s\r\n",
      " 142785 64171     cutoff   46         0.72922    0.52399  28.1%   6.2  410s\r\n",
      " 143623 64511     cutoff   49         0.72922    0.52454  28.1%   6.2  415s\r\n",
      " 144479 64895     cutoff   75         0.72922    0.52514  28.0%   6.2  420s\r\n",
      " 145631 65247     cutoff   50         0.72922    0.52582  27.9%   6.2  425s\r\n",
      " 146847 65683     cutoff   56         0.72922    0.52654  27.8%   6.2  431s\r\n",
      " 147572 65930     cutoff   64         0.72922    0.52697  27.7%   6.2  436s\r\n",
      " 148332 66227    0.67516   44   13    0.72922    0.52735  27.7%   6.2  440s\r\n",
      " 149340 66653    0.60448   40   14    0.72922    0.52785  27.6%   6.2  446s\r\n",
      " 150070 66937    0.71508   48    3    0.72922    0.52823  27.6%   6.3  450s\r\n",
      " 150806 67245     cutoff   43         0.72922    0.52858  27.5%   6.3  455s\r\n",
      " 151932 67665     cutoff   71         0.72922    0.52910  27.4%   6.3  461s\r\n",
      " 152681 67870     cutoff   46         0.72922    0.52957  27.4%   6.3  465s\r\n",
      " 153750 68239     cutoff   45         0.72922    0.53013  27.3%   6.3  472s\r\n",
      " 154532 68533     cutoff   43         0.72922    0.53053  27.2%   6.3  476s\r\n",
      " 155290 68837    0.71744   55    8    0.72922    0.53093  27.2%   6.3  481s\r\n",
      " 156005 69083    0.72753   46    2    0.72922    0.53138  27.1%   6.4  485s\r\n",
      " 156878 69359     cutoff   43         0.72922    0.53161  27.1%   6.4  490s\r\n",
      " 157866 69733     cutoff   75         0.72922    0.53222  27.0%   6.4  496s\r\n",
      " 158526 69908     cutoff   45         0.72922    0.53269  27.0%   6.4  501s\r\n",
      " 159326 70204     cutoff   51         0.72922    0.53298  26.9%   6.4  505s\r\n",
      " 160407 70653     cutoff   52         0.72922    0.53378  26.8%   6.4  512s\r\n",
      " 161152 70908    0.59332   39   10    0.72922    0.53429  26.7%   6.4  516s\r\n",
      " 161895 71184    0.62751   45    5    0.72922    0.53461  26.7%   6.4  521s\r\n",
      " 162682 71472     cutoff   43         0.72922    0.53515  26.6%   6.5  525s\r\n",
      " 163308 71646    0.64118   46   24    0.72922    0.53556  26.6%   6.5  530s\r\n",
      " 164048 71883    0.63036   44   14    0.72922    0.53611  26.5%   6.5  535s\r\n",
      " 165207 72256    0.71679   44   26    0.72922    0.53677  26.4%   6.5  541s\r\n",
      " 165920 72517    0.71998   55   10    0.72922    0.53718  26.3%   6.5  546s\r\n",
      " 166602 72732    0.68428   51   13    0.72922    0.53771  26.3%   6.5  551s\r\n",
      " 167369 72982    0.69058   41   19    0.72922    0.53817  26.2%   6.5  556s\r\n",
      " 168088 73234    0.68049   49   10    0.72922    0.53846  26.2%   6.5  562s\r\n",
      " 168881 73482    0.72706   45   14    0.72922    0.53893  26.1%   6.5  567s\r\n",
      " 169332 73598     cutoff   45         0.72922    0.53915  26.1%   6.6  570s\r\n",
      " 170050 73802     cutoff   50         0.72922    0.53950  26.0%   6.6  575s\r\n",
      " 170741 74011    0.71959   47   11    0.72922    0.53993  26.0%   6.6  580s\r\n",
      " 171507 74236     cutoff   47         0.72922    0.54040  25.9%   6.6  585s\r\n",
      " 172159 74436     cutoff   50         0.72922    0.54085  25.8%   6.6  590s\r\n",
      " 172942 74665     cutoff   54         0.72922    0.54134  25.8%   6.6  595s\r\n",
      " 173686 74913    0.63876   40   14    0.72922    0.54171  25.7%   6.6  600s\r\n",
      "\r\n",
      "Cutting planes:\r\n",
      "  Gomory: 4\r\n",
      "  MIR: 4\r\n",
      "  Lazy constraints: 2965\r\n",
      "\r\n",
      "Explored 173947 nodes (1151638 simplex iterations) in 600.03 seconds\r\n",
      "Thread count was 4 (of 4 available processors)\r\n",
      "\r\n",
      "Solution count 8: 0.729223 0.755987 0.764992 ... 1.68408\r\n",
      "\r\n",
      "Time limit reached\r\n",
      "Best objective 7.292226242820e-01, best bound 5.417831787658e-01, gap 25.7040%\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mNot solved to optimality, status: UserLimit\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\r\n",
      "Optimize a model with 2 rows, 101 columns and 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [2e-06, 1e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  Bounds range     [1e+00, 1e+00]\r\n",
      "  RHS range        [1e+00, 1e+01]\r\n",
      "Presolve time: 0.00s\r\n",
      "Presolved: 2 rows, 101 columns, 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "\r\n",
      "Root relaxation: objective 2.384970e-01, 7 iterations, 0.00 seconds\r\n",
      "\r\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\r\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\r\n",
      "\r\n",
      "     0     0    0.24770    0    2          -    0.24770      -     -    0s\r\n",
      "H    0     0                       1.2498747    0.24770  80.2%     -    0s\r\n",
      "     0     0    0.29074    0    5    1.24987    0.29074  76.7%     -    0s\r\n",
      "H    0     0                       1.1241130    0.29074  74.1%     -    0s\r\n",
      "     0     0    0.29871    0    6    1.12411    0.29871  73.4%     -    0s\r\n",
      "     0     0    0.30118    0    5    1.12411    0.30118  73.2%     -    0s\r\n",
      "     0     0    0.30434    0    6    1.12411    0.30434  72.9%     -    0s\r\n",
      "     0     0    0.30616    0    7    1.12411    0.30616  72.8%     -    0s\r\n",
      "     0     0    0.30835    0    7    1.12411    0.30835  72.6%     -    0s\r\n",
      "     0     0    0.30850    0    8    1.12411    0.30850  72.6%     -    0s\r\n",
      "     0     0    0.30988    0    8    1.12411    0.30988  72.4%     -    0s\r\n",
      "     0     2    0.31045    0    8    1.12411    0.31045  72.4%     -    0s\r\n",
      "*  110    95              28       0.9957792    0.34110  65.7%   2.1    0s\r\n",
      "H  749   610                       0.9268838    0.35905  61.3%   2.0    0s\r\n",
      " 14641 10748    0.87498   75    -    0.92688    0.47794  48.4%   3.5    5s\r\n",
      " 19319 14300    0.50173   24   15    0.92688    0.48756  47.4%   3.6   10s\r\n",
      "*19591 13726              36       0.8599615    0.48874  43.2%   3.6   13s\r\n",
      "*19828 13095              55       0.8367907    0.49645  40.7%   3.6   14s\r\n",
      " 20783 13432     cutoff   93         0.83679    0.51228  38.8%   3.7   15s\r\n",
      " 26549 15853    0.81271   64    2    0.83679    0.53441  36.1%   3.7   20s\r\n",
      "*28120 15827              53       0.8306487    0.53773  35.3%   3.8   21s\r\n",
      "*30800 14379              35       0.7653341    0.54259  29.1%   3.9   23s\r\n",
      " 32195 14780    0.75634   47    4    0.76533    0.54542  28.7%   4.0   25s\r\n",
      " 36398 15986     cutoff   73         0.76533    0.55291  27.8%   4.1   30s\r\n",
      " 39183 16800    0.65401   37   11    0.76533    0.55800  27.1%   4.3   35s\r\n",
      " 42904 17697    0.73581   41    3    0.76533    0.56443  26.2%   4.4   40s\r\n",
      " 45866 18357    0.72302   36    8    0.76533    0.56911  25.6%   4.5   45s\r\n",
      " 48604 18927    0.71456   41   12    0.76533    0.57217  25.2%   4.7   50s\r\n",
      " 51837 19562     cutoff   47         0.76533    0.57614  24.7%   4.8   55s\r\n",
      " 54746 20205     cutoff   45         0.76533    0.57993  24.2%   4.9   60s\r\n",
      " 57324 21417    0.67542   40    9    0.76533    0.58305  23.8%   5.0   65s\r\n",
      " 59895 22615     cutoff   42         0.76533    0.58596  23.4%   5.1   70s\r\n",
      " 62604 23860     cutoff   45         0.76533    0.58899  23.0%   5.2   75s\r\n",
      " 64577 24701    0.62740   34   13    0.76533    0.59101  22.8%   5.3   80s\r\n",
      " 66956 25607    0.69768   39    5    0.76533    0.59339  22.5%   5.3   85s\r\n",
      " 69043 26488     cutoff   83         0.76533    0.59514  22.2%   5.4   90s\r\n",
      " 71172 27381     cutoff   42         0.76533    0.59705  22.0%   5.4   95s\r\n",
      " 72896 28081    0.66482   33   13    0.76533    0.59848  21.8%   5.5  100s\r\n",
      " 75317 29047     cutoff   43         0.76533    0.60078  21.5%   5.6  106s\r\n",
      " 76701 29534     cutoff   40         0.76533    0.60199  21.3%   5.6  110s\r\n",
      " 78451 30113     cutoff   38         0.76533    0.60347  21.1%   5.6  115s\r\n",
      " 80282 30723     cutoff   42         0.76533    0.60528  20.9%   5.7  120s\r\n",
      " 82435 31534     cutoff   48         0.76533    0.60727  20.7%   5.7  125s\r\n",
      " 84280 32166     cutoff   37         0.76533    0.60894  20.4%   5.8  130s\r\n",
      " 86117 32767    0.69057   40   12    0.76533    0.61051  20.2%   5.8  135s\r\n",
      " 88272 33422    0.73648   46    5    0.76533    0.61242  20.0%   5.9  140s\r\n",
      " 90042 33892     cutoff   40         0.76533    0.61377  19.8%   5.9  145s\r\n",
      " 91790 34439    0.74442   40    5    0.76533    0.61513  19.6%   5.9  150s\r\n",
      " 93632 34976    0.71093   37    6    0.76533    0.61650  19.4%   6.0  155s\r\n",
      " 95384 35513     cutoff   45         0.76533    0.61779  19.3%   6.0  161s\r\n",
      " 96954 35985    0.75887   50    3    0.76533    0.61902  19.1%   6.0  165s\r\n",
      " 98322 36367     cutoff   45         0.76533    0.62017  19.0%   6.1  170s\r\n",
      " 99761 36731    0.67922   38    8    0.76533    0.62128  18.8%   6.1  175s\r\n",
      " 101222 37130     cutoff   38         0.76533    0.62248  18.7%   6.1  180s\r\n",
      " 102594 37477    0.76458   35   13    0.76533    0.62357  18.5%   6.2  186s\r\n",
      " 103306 37673    0.70310   32    6    0.76533    0.62412  18.5%   6.2  191s\r\n",
      " 104358 37920    0.71572   36    5    0.76533    0.62483  18.4%   6.2  195s\r\n",
      " 105831 38275    0.71522   39   18    0.76533    0.62583  18.2%   6.3  201s\r\n",
      " 106954 38568    0.68548   38   14    0.76533    0.62664  18.1%   6.3  205s\r\n",
      " 108071 38855    0.74164   45   13    0.76533    0.62735  18.0%   6.3  210s\r\n",
      " 109728 39196     cutoff   44         0.76533    0.62865  17.9%   6.3  216s\r\n",
      " 110902 39453     cutoff   64         0.76533    0.62940  17.8%   6.3  220s\r\n",
      " 112050 39717    0.69784   38   15    0.76533    0.63024  17.7%   6.3  225s\r\n",
      " 113375 40030    0.72026   41    5    0.76533    0.63102  17.5%   6.4  231s\r\n",
      " 114461 40232     cutoff   52         0.76533    0.63181  17.4%   6.4  235s\r\n",
      " 115986 40524    0.75784   44    -    0.76533    0.63272  17.3%   6.4  241s\r\n",
      " 117189 40799     cutoff   50         0.76533    0.63337  17.2%   6.4  245s\r\n",
      " 118387 41135    0.73031   38   11    0.76533    0.63401  17.2%   6.5  250s\r\n",
      " 119904 41439    0.71154   33    8    0.76533    0.63483  17.1%   6.5  256s\r\n",
      " 120893 41607     cutoff   45         0.76533    0.63546  17.0%   6.5  260s\r\n",
      " 122016 41751     cutoff   39         0.76533    0.63613  16.9%   6.5  265s\r\n",
      " 123211 41943    0.75769   42    9    0.76533    0.63697  16.8%   6.5  270s\r\n",
      " 124282 42138     cutoff   43         0.76533    0.63774  16.7%   6.6  275s\r\n",
      " 125058 42315    0.71309   33   15    0.76533    0.63808  16.6%   6.6  280s\r\n",
      " 125916 42408     cutoff   57         0.76533    0.63869  16.5%   6.6  285s\r\n",
      " 127392 42656    0.71411   41   13    0.76533    0.63958  16.4%   6.6  291s\r\n",
      " 128472 42878     cutoff   38         0.76533    0.64024  16.3%   6.6  296s\r\n",
      " 129632 43088    0.73282   44   16    0.76533    0.64110  16.2%   6.6  301s\r\n",
      " 130795 43269     cutoff   45         0.76533    0.64184  16.1%   6.6  305s\r\n",
      " 131999 43493    0.66280   37   12    0.76533    0.64248  16.1%   6.6  311s\r\n",
      " 133130 43684     cutoff   43         0.76533    0.64319  16.0%   6.7  316s\r\n",
      " 134232 43845     cutoff   46         0.76533    0.64387  15.9%   6.7  321s\r\n",
      " 135411 44027     cutoff   48         0.76533    0.64446  15.8%   6.7  326s\r\n",
      " 136145 44127    0.75539   42   12    0.76533    0.64496  15.7%   6.7  330s\r\n",
      " 137284 44373     cutoff   76         0.76533    0.64561  15.6%   6.7  335s\r\n",
      " 138386 44555     cutoff   40         0.76533    0.64619  15.6%   6.7  340s\r\n",
      " 139496 44689    0.67958   35   11    0.76533    0.64677  15.5%   6.8  345s\r\n",
      " 140675 44886    0.72626   40    7    0.76533    0.64733  15.4%   6.8  350s\r\n",
      " 141865 45077    0.73202   37   13    0.76533    0.64802  15.3%   6.8  355s\r\n",
      " 142989 45223     cutoff   42         0.76533    0.64866  15.2%   6.8  360s\r\n",
      " 144120 45418     cutoff   48         0.76533    0.64936  15.2%   6.8  365s\r\n",
      " 145123 45585     cutoff   35         0.76533    0.64978  15.1%   6.8  371s\r\n",
      " 146259 45738    0.75220   35   13    0.76533    0.65046  15.0%   6.8  376s\r\n",
      " 147321 45890    0.72319   37   13    0.76533    0.65102  14.9%   6.9  381s\r\n",
      " 148103 45983    0.76522   44    8    0.76533    0.65143  14.9%   6.9  385s\r\n",
      " 149255 46126     cutoff   36         0.76533    0.65203  14.8%   6.9  390s\r\n",
      " 150480 46320    0.71458   38   15    0.76533    0.65266  14.7%   6.9  395s\r\n",
      " 151529 46401     cutoff   61         0.76533    0.65326  14.6%   6.9  400s\r\n",
      " 152737 46547    0.75780   42   10    0.76533    0.65391  14.6%   6.9  405s\r\n",
      " 153918 46665     cutoff   46         0.76533    0.65452  14.5%   6.9  411s\r\n",
      " 154709 46744     cutoff   47         0.76533    0.65489  14.4%   6.9  415s\r\n",
      " 155810 46841     cutoff   44         0.76533    0.65551  14.3%   6.9  420s\r\n",
      " 156990 46931     cutoff   40         0.76533    0.65614  14.3%   7.0  426s\r\n",
      " 158182 46999    0.71555   44    6    0.76533    0.65681  14.2%   7.0  431s\r\n",
      " 159041 47145    0.75967   41   10    0.76533    0.65725  14.1%   7.0  435s\r\n",
      " 160192 47220    0.74615   38    6    0.76533    0.65783  14.0%   7.0  441s\r\n",
      " 161000 47302     cutoff   42         0.76533    0.65827  14.0%   7.0  445s\r\n",
      "*161916 40413              41       0.7426967    0.65870  11.3%   7.0  448s\r\n",
      " 162194 40437     cutoff   38         0.74270    0.65894  11.3%   7.0  452s\r\n",
      " 162631 40357    0.70602   34   12    0.74270    0.65918  11.2%   7.0  456s\r\n",
      " 163342 40276     cutoff   42         0.74270    0.65980  11.2%   7.0  460s\r\n",
      " 164383 40149    0.72758   36    9    0.74270    0.66055  11.1%   7.0  466s\r\n",
      " 165080 40055    0.70875   38    7    0.74270    0.66115  11.0%   7.0  470s\r\n",
      " 166130 39955    0.72877   40   12    0.74270    0.66188  10.9%   7.1  476s\r\n",
      " 166788 39894    0.69818   36   10    0.74270    0.66242  10.8%   7.1  481s\r\n",
      " 167570 39839     cutoff   42         0.74270    0.66293  10.7%   7.1  485s\r\n",
      " 168565 39682     cutoff   40         0.74270    0.66376  10.6%   7.1  491s\r\n",
      " 169317 39620     cutoff   45         0.74270    0.66427  10.6%   7.1  495s\r\n",
      " 170012 39526     cutoff   44         0.74270    0.66485  10.5%   7.1  500s\r\n",
      " 171112 39411     cutoff   39         0.74270    0.66577  10.4%   7.1  506s\r\n",
      " 171788 39330    0.72384   38   15    0.74270    0.66618  10.3%   7.1  510s\r\n",
      " 172768 39172     cutoff   36         0.74270    0.66701  10.2%   7.1  517s\r\n",
      " 173445 39073    0.73218   39   14    0.74270    0.66745  10.1%   7.1  522s\r\n",
      " 174045 38986    0.71145   38    4    0.74270    0.66790  10.1%   7.2  526s\r\n",
      " 174768 38923     cutoff   35         0.74270    0.66848  10.0%   7.2  531s\r\n",
      " 175247 38797     cutoff   48         0.74270    0.66883  9.95%   7.2  536s\r\n",
      " 175998 38693    0.72194   44    6    0.74270    0.66927  9.89%   7.2  540s\r\n",
      " 176736 38602    0.71775   38   19    0.74270    0.66973  9.82%   7.2  545s\r\n",
      " 177487 38499     cutoff   41         0.74270    0.67027  9.75%   7.2  550s\r\n",
      " 178541 38369     cutoff   35         0.74270    0.67090  9.67%   7.2  556s\r\n",
      " 179167 38251     cutoff   38         0.74270    0.67144  9.59%   7.2  560s\r\n",
      " 179837 38163     cutoff   37         0.74270    0.67187  9.54%   7.2  565s\r\n",
      " 180815 37980     cutoff   45         0.74270    0.67254  9.45%   7.2  572s\r\n",
      " 181461 37869     cutoff   41         0.74270    0.67304  9.38%   7.2  575s\r\n",
      " 182385 37701     cutoff   39         0.74270    0.67378  9.28%   7.2  581s\r\n",
      " 183036 37581    0.71477   44    5    0.74270    0.67425  9.22%   7.3  585s\r\n",
      " 183975 37400    0.73310   35   20    0.74270    0.67507  9.11%   7.3  591s\r\n",
      " 184546 37260    0.72453   37   15    0.74270    0.67551  9.05%   7.3  595s\r\n",
      " 185529 37138     cutoff   37         0.74270    0.67619  8.96%   7.3  600s\r\n",
      "\r\n",
      "Cutting planes:\r\n",
      "  Gomory: 5\r\n",
      "  MIR: 2\r\n",
      "  Lazy constraints: 2091\r\n",
      "\r\n",
      "Explored 185599 nodes (1351455 simplex iterations) in 600.02 seconds\r\n",
      "Thread count was 4 (of 4 available processors)\r\n",
      "\r\n",
      "Solution count 9: 0.742697 0.765334 0.830649 ... 1.24987\r\n",
      "\r\n",
      "Time limit reached\r\n",
      "Best objective 7.426966705500e-01, best bound 6.762149857034e-01, gap 8.9514%\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mNot solved to optimality, status: UserLimit\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\r\n",
      "Optimize a model with 2 rows, 101 columns and 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [4e-06, 1e+00]\r\n",
      "  Objective range  [1e+00, 1e+00]\r\n",
      "  Bounds range     [1e+00, 1e+00]\r\n",
      "  RHS range        [1e+00, 1e+01]\r\n",
      "Presolve time: 0.00s\r\n",
      "Presolved: 2 rows, 101 columns, 201 nonzeros\r\n",
      "Variable types: 1 continuous, 100 integer (100 binary)\r\n",
      "\r\n",
      "Root relaxation: objective 0.000000e+00, 9 iterations, 0.00 seconds\r\n",
      "\r\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\r\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\r\n",
      "\r\n",
      "     0     0    0.00000    0    2          -    0.00000      -     -    0s\r\n",
      "H    0     0                       1.8535687    0.00000   100%     -    0s\r\n",
      "H    0     0                       1.4751417    0.00000   100%     -    0s\r\n",
      "     0     0    0.00000    0    3    1.47514    0.00000   100%     -    0s\r\n",
      "     0     0    0.00000    0    2    1.47514    0.00000   100%     -    0s\r\n",
      "H    0     0                       1.0104513    0.00000   100%     -    0s\r\n",
      "     0     2    0.00000    0    3    1.01045    0.00000   100%     -    0s\r\n",
      "*  211   136              15       0.9217209    0.00000   100%   2.2    0s\r\n",
      "*  713   447              62       0.9214409    0.07165  92.2%   2.7    0s\r\n",
      "H  929   604                       0.8484241    0.13883  83.6%   2.8    0s\r\n",
      "* 1055   654              28       0.7440046    0.18889  74.6%   3.2    1s\r\n",
      "* 1106   631              31       0.7379725    0.19202  74.0%   3.2    1s\r\n",
      "* 1141   606              33       0.7362722    0.19202  73.9%   3.2    1s\r\n",
      "* 1325   652              30       0.7245059    0.19202  73.5%   3.3    1s\r\n",
      "* 1388   631              29       0.7201772    0.20508  71.5%   3.4    1s\r\n",
      "* 7957  5492              37       0.7061983    0.30265  57.1%   3.8    3s\r\n",
      "  9942  7090     cutoff   51         0.70620    0.31951  54.8%   3.9    5s\r\n",
      " 21009 15607    0.67680   66   15    0.70620    0.35960  49.1%   4.4   10s\r\n",
      " 29134 21696     cutoff   94         0.70620    0.37566  46.8%   4.8   15s\r\n",
      " 36021 26894    0.56775   62    2    0.70620    0.38605  45.3%   5.0   24s\r\n",
      " 36023 26895    0.46046   31   14    0.70620    0.38605  45.3%   5.0   25s\r\n",
      "H36023 25550                       0.6687883    0.38605  42.3%   5.0   25s\r\n",
      "H36035 24280                       0.6541020    0.40262  38.4%   5.0   27s\r\n",
      " 36586 24539    0.49539   43    6    0.65410    0.42102  35.6%   5.0   30s\r\n",
      " 40796 26259     cutoff   93         0.65410    0.44780  31.5%   5.0   35s\r\n",
      " 45252 27930    0.63939   65   13    0.65410    0.45701  30.1%   5.1   40s\r\n",
      " 49444 29434     cutoff   73         0.65410    0.46376  29.1%   5.2   45s\r\n",
      " 53015 30553     cutoff   42         0.65410    0.46872  28.3%   5.3   50s\r\n",
      " 56100 31434     cutoff   47         0.65410    0.47245  27.8%   5.4   55s\r\n",
      " 59284 32375    0.61707   53    8    0.65410    0.47640  27.2%   5.5   60s\r\n",
      " 62910 33436     cutoff   59         0.65410    0.48018  26.6%   5.5   65s\r\n",
      " 63730 33674    0.55484   34    9    0.65410    0.48150  26.4%   5.5   70s\r\n",
      " 66869 34459     cutoff   75         0.65410    0.48496  25.9%   5.6   75s\r\n",
      " 69658 35070     cutoff   42         0.65410    0.48761  25.5%   5.6   80s\r\n",
      "*71003 33936              44       0.6502525    0.48877  24.8%   5.7   82s\r\n",
      " 72104 34141    0.60876   48    8    0.65025    0.49006  24.6%   5.7   85s\r\n",
      " 74761 34571     cutoff   39         0.65025    0.49311  24.2%   5.7   90s\r\n",
      " 77147 34958    0.64093   72    -    0.65025    0.49588  23.7%   5.8   95s\r\n",
      " 79591 35447    0.64822   43    6    0.65025    0.49812  23.4%   5.8  100s\r\n",
      " 81955 35781    0.60275   48   13    0.65025    0.49993  23.1%   5.9  105s\r\n",
      " 84054 36035     cutoff   43         0.65025    0.50198  22.8%   5.9  110s\r\n",
      "*85604 33753              42       0.6406551    0.50295  21.5%   5.9  113s\r\n",
      " 86502 33834     cutoff   48         0.64066    0.50399  21.3%   5.9  115s\r\n",
      " 88583 34093    0.55382   44    8    0.64066    0.50574  21.1%   6.0  120s\r\n",
      " 90655 34281     cutoff   61         0.64066    0.50784  20.7%   6.0  125s\r\n",
      " 92476 34374    0.56775   37   10    0.64066    0.50918  20.5%   6.0  130s\r\n",
      " 94277 34496     cutoff   47         0.64066    0.51069  20.3%   6.1  136s\r\n",
      " 95635 34510     cutoff   44         0.64066    0.51200  20.1%   6.1  140s\r\n",
      " 97495 34606     cutoff   41         0.64066    0.51370  19.8%   6.1  145s\r\n",
      " 99321 34687    0.60620   43   10    0.64066    0.51518  19.6%   6.2  150s\r\n",
      "*100536 33965              48       0.6391150    0.51631  19.2%   6.2  153s\r\n",
      " 101213 34203     cutoff   41         0.63912    0.51700  19.1%   6.2  158s\r\n",
      " 101476 34286    0.63169   53    8    0.63912    0.51719  19.1%   6.2  160s\r\n",
      " 102875 34773     cutoff   46         0.63912    0.51816  18.9%   6.2  165s\r\n",
      " 104353 35267     cutoff   46         0.63912    0.51936  18.7%   6.2  170s\r\n",
      " 106316 35908    0.63372   49    4    0.63912    0.52090  18.5%   6.3  175s\r\n",
      " 108141 36537    0.58047   44    9    0.63912    0.52213  18.3%   6.3  180s\r\n",
      " 110011 37088     cutoff   41         0.63912    0.52326  18.1%   6.3  185s\r\n",
      " 111823 37618     cutoff   47         0.63912    0.52460  17.9%   6.3  190s\r\n",
      " 113768 38220     cutoff   53         0.63912    0.52584  17.7%   6.4  195s\r\n",
      " 115576 38710     cutoff   54         0.63912    0.52699  17.5%   6.4  200s\r\n",
      " 116971 39152    0.60407   41    6    0.63912    0.52793  17.4%   6.4  205s\r\n",
      " 118841 39669     cutoff   55         0.63912    0.52913  17.2%   6.4  210s\r\n",
      " 120356 40083     cutoff   53         0.63912    0.53004  17.1%   6.4  215s\r\n",
      " 122177 40590    0.63544   42   17    0.63912    0.53118  16.9%   6.5  221s\r\n",
      " 123679 41017     cutoff   48         0.63912    0.53215  16.7%   6.5  226s\r\n",
      " 125237 41408    0.60611   46   13    0.63912    0.53304  16.6%   6.5  231s\r\n",
      " 126419 41726     cutoff   56         0.63912    0.53363  16.5%   6.5  235s\r\n",
      " 127961 42113    0.55269   36   11    0.63912    0.53443  16.4%   6.5  240s\r\n",
      " 129499 42509     cutoff   45         0.63912    0.53515  16.3%   6.5  245s\r\n",
      " 131029 42862    0.61769   47    9    0.63912    0.53609  16.1%   6.6  251s\r\n",
      " 132555 43209     cutoff   52         0.63912    0.53719  15.9%   6.6  256s\r\n",
      " 134074 43525     cutoff   44         0.63912    0.53808  15.8%   6.6  261s\r\n",
      " 135221 43862    0.59952   49    7    0.63912    0.53870  15.7%   6.6  265s\r\n",
      " 136446 44140    0.62248   60    4    0.63912    0.53941  15.6%   6.6  270s\r\n",
      " 138000 44462    0.61504   42   10    0.63912    0.54010  15.5%   6.6  276s\r\n",
      " 139150 44732    0.57679   38    8    0.63912    0.54067  15.4%   6.6  280s\r\n",
      " 140673 45036     cutoff   50         0.63912    0.54158  15.3%   6.7  285s\r\n",
      "*141511 45167              36       0.6390519    0.54203  15.2%   6.7  287s\r\n",
      " 141821 45281     cutoff   39         0.63905    0.54227  15.1%   6.7  292s\r\n",
      " 142177 45333    0.60475   42    6    0.63905    0.54244  15.1%   6.7  295s\r\n",
      " 143698 45692    0.62061   46    9    0.63905    0.54314  15.0%   6.7  300s\r\n",
      " 145292 46053    0.60964   40    6    0.63905    0.54390  14.9%   6.7  306s\r\n",
      " 146452 46220    0.62377   46    4    0.63905    0.54445  14.8%   6.7  310s\r\n",
      " 148004 46495    0.63380   47    4    0.63905    0.54522  14.7%   6.7  316s\r\n",
      " 149146 46727     cutoff   57         0.63905    0.54572  14.6%   6.7  321s\r\n",
      " 150280 46917    0.62107   43    7    0.63905    0.54627  14.5%   6.7  325s\r\n",
      " 151388 47107     cutoff   47         0.63905    0.54683  14.4%   6.8  330s\r\n",
      " 152836 47400     cutoff   47         0.63905    0.54742  14.3%   6.8  336s\r\n",
      " 154020 47598    0.61941   48   10    0.63905    0.54800  14.2%   6.8  341s\r\n",
      " 154793 47686    0.60483   48    8    0.63905    0.54832  14.2%   6.8  345s\r\n",
      " 156383 47915    0.62705   47    7    0.63905    0.54900  14.1%   6.8  351s\r\n",
      " 157569 48103    0.62512   43   12    0.63905    0.54954  14.0%   6.8  356s\r\n",
      " 158730 48294     cutoff   58         0.63905    0.55003  13.9%   6.8  361s\r\n",
      " 159834 48423    0.60649   46    7    0.63905    0.55058  13.8%   6.8  365s\r\n",
      " 161018 48634     cutoff   50         0.63905    0.55113  13.8%   6.8  370s\r\n",
      " 162553 48918     cutoff   40         0.63905    0.55168  13.7%   6.9  376s\r\n",
      " 163750 49104    0.60859   42   14    0.63905    0.55215  13.6%   6.9  381s\r\n",
      " 164952 49284     cutoff   49         0.63905    0.55271  13.5%   6.9  386s\r\n",
      "*165277 46892              42       0.6323947    0.55290  12.6%   6.9  386s\r\n",
      " 165735 46914     cutoff   46         0.63239    0.55314  12.5%   6.9  390s\r\n",
      " 166832 47000     cutoff   49         0.63239    0.55368  12.4%   6.9  395s\r\n",
      " 167990 47113    0.62824   46    6    0.63239    0.55418  12.4%   6.9  400s\r\n",
      " 169127 47210     cutoff   52         0.63239    0.55478  12.3%   6.9  405s\r\n",
      " 170306 47271     cutoff   48         0.63239    0.55536  12.2%   6.9  410s\r\n",
      " 171474 47354     cutoff   57         0.63239    0.55594  12.1%   6.9  416s\r\n",
      " 172634 47450     cutoff   47         0.63239    0.55649  12.0%   6.9  421s\r\n",
      " 173735 47498    0.57886   40   10    0.63239    0.55699  11.9%   6.9  426s\r\n",
      " 174919 47565     cutoff   45         0.63239    0.55759  11.8%   7.0  431s\r\n",
      " 176121 47614     cutoff   41         0.63239    0.55816  11.7%   7.0  436s\r\n",
      " 177190 47630    0.60496   44    7    0.63239    0.55878  11.6%   7.0  441s\r\n",
      " 177984 47655     cutoff   43         0.63239    0.55916  11.6%   7.0  445s\r\n",
      " 179177 47697    0.62642   44    4    0.63239    0.55975  11.5%   7.0  450s\r\n",
      " 180364 47747     cutoff   50         0.63239    0.56021  11.4%   7.0  456s\r\n",
      " 181135 47768    0.60359   42   11    0.63239    0.56057  11.4%   7.0  460s\r\n",
      " 182262 47757     cutoff   41         0.63239    0.56106  11.3%   7.0  465s\r\n",
      " 183417 47784    0.62469   38   11    0.63239    0.56161  11.2%   7.0  471s\r\n",
      " 184157 47792     cutoff   47         0.63239    0.56193  11.1%   7.0  475s\r\n",
      " 185335 47796    0.63143   46    -    0.63239    0.56244  11.1%   7.0  481s\r\n",
      " 186114 47768    0.57989   41    7    0.63239    0.56286  11.0%   7.0  485s\r\n",
      " 187217 47712     cutoff   41         0.63239    0.56342  10.9%   7.0  491s\r\n",
      " 187985 47707     cutoff   44         0.63239    0.56379  10.8%   7.1  495s\r\n",
      " 189077 47705     cutoff   43         0.63239    0.56430  10.8%   7.1  501s\r\n",
      " 189882 47672     cutoff   53         0.63239    0.56465  10.7%   7.1  506s\r\n",
      " 190647 47642    0.60487   39    9    0.63239    0.56503  10.7%   7.1  510s\r\n",
      " 191788 47628    0.61592   46    8    0.63239    0.56554  10.6%   7.1  516s\r\n",
      " 192544 47614     cutoff   45         0.63239    0.56593  10.5%   7.1  520s\r\n",
      " 193734 47610     cutoff   45         0.63239    0.56645  10.4%   7.1  526s\r\n",
      " 194459 47569     cutoff   46         0.63239    0.56688  10.4%   7.1  530s\r\n",
      " 195615 47536     cutoff   49         0.63239    0.56741  10.3%   7.1  536s\r\n",
      " 196367 47528    0.62971   42    3    0.63239    0.56776  10.2%   7.1  540s\r\n",
      " 197496 47513     cutoff   43         0.63239    0.56820  10.2%   7.1  546s\r\n",
      " 198203 47474    0.60111   50    8    0.63239    0.56850  10.1%   7.1  550s\r\n",
      " 199306 47432    0.57761   36    8    0.63239    0.56892  10.0%   7.1  556s\r\n",
      " 200041 47387    0.60386   42   10    0.63239    0.56924  10.0%   7.1  561s\r\n",
      " 200787 47336     cutoff   41         0.63239    0.56956  9.94%   7.2  565s\r\n",
      " 201963 47259     cutoff   50         0.63239    0.57007  9.86%   7.2  571s\r\n",
      " 202679 47193     cutoff   48         0.63239    0.57040  9.80%   7.2  575s\r\n",
      " 203821 47123     cutoff   40         0.63239    0.57088  9.73%   7.2  581s\r\n",
      " 204586 47134     cutoff   40         0.63239    0.57120  9.68%   7.2  590s\r\n",
      " 205254 47048     cutoff   45         0.63239    0.57151  9.63%   7.2  596s\r\n",
      " 205734 47011     cutoff   57         0.63239    0.57173  9.59%   7.2  600s\r\n",
      "\r\n",
      "Cutting planes:\r\n",
      "  Gomory: 4\r\n",
      "  Lazy constraints: 1924\r\n",
      "\r\n",
      "Explored 205882 nodes (1478662 simplex iterations) in 600.02 seconds\r\n",
      "Thread count was 4 (of 4 available processors)\r\n",
      "\r\n",
      "Solution count 10: 0.632395 0.639052 0.639115 ... 0.724506\r\n",
      "\r\n",
      "Time limit reached\r\n",
      "Best objective 6.323947055306e-01, best bound 5.717628473894e-01, gap 9.5877%\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mNot solved to optimality, status: UserLimit\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "k = 10 \n",
    "y = myDataY\n",
    "l,p= size(Matrix(myDataX))\n",
    "\n",
    "w = Array{Float64}(myDataB)\n",
    "ks = []\n",
    "As = []\n",
    "Fs = []\n",
    "scores = []\n",
    "\n",
    "\n",
    "for i in [100, 90, 80, 70, 60, 50, 40, 30, 20]\n",
    "    push!(ks, i)\n",
    "    X = Matrix(myDataX[1:i, 1:p])\n",
    "    y = Array{Float64}(y[1:i])\n",
    "    betaTS = sparseregression(X,y,k)    \n",
    "    (A, F)= detection_rate(betaTS, w)\n",
    "    score = evaluate(X,y,betaTS)\n",
    "    push!(As, A)\n",
    "    push!(Fs, F)\n",
    "    push!(scores, score)\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9×4 Array{Real,2}:\n",
       " 100  1.0  0.0  5.06335\n",
       "  90  1.0  0.0  4.73272\n",
       "  80  1.0  0.0  4.58688\n",
       "  70  1.0  0.0  4.41564\n",
       "  60  1.0  0.0  4.09611\n",
       "  50  1.0  0.0  3.84741\n",
       "  40  0.7  0.3  5.06185\n",
       "  30  1.0  0.0  3.21666\n",
       "  20  0.3  0.7  2.83241"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " table = hcat(ks, As, Fs, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Quality of solution goes down as you decrease the number of data points. The run time of the code increases as you decrease the number of points used, particularly at n = 40 and fewer where it hits the user limit. From n = 40, the time limit is reached so the solution may not have to optimality. \n",
    "The accuracy and false positive rates stay fairly accurate until n = 40, at which point they stop being accurate of 100% and false positive rate of 0%. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
