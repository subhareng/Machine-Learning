{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using JuMP\n",
    "using Gurobi\n",
    "using Distributions\n",
    "using Ipopt\n",
    "using MLBase\n",
    "using DataFrames\n",
    "using DataFramesMeta\n",
    "using MLDataUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myData1 = readtable(\"C:/Users/subha/Desktop/ML HW -3/magic04.csv\",header=false);\n",
    "myData2 = readtable(\"C:/Users/subha/Desktop/ML HW -3/parkinsons_updrs.csv\",header=false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gamma1back0 (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gamma1back0(y)\n",
    "    newpredcol = []\n",
    "    m = length(y)\n",
    "    for i in 1:m\n",
    "        if y[i]==\"g\"\n",
    "            push!(newpredcol,1)\n",
    "        else\n",
    "            push!(newpredcol,0)\n",
    "        end\n",
    "    end\n",
    "    newpredcol = Array{Float64}(newpredcol)\n",
    "    return newpredcol\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = myData1[1:end-1];\n",
    "Y = myData1[end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logistic_regression (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function logistic_regression(X, y)\n",
    "  n, p = size(X)\n",
    "\n",
    "  # Convert y to (-1, +1)\n",
    "  @assert(extrema(y) == (0, 1), \"y must be all 0s and 1s\")\n",
    "  Y = y * 2 - 1\n",
    "  @assert(extrema(Y) == (-1, 1))\n",
    "\n",
    "  # Create the model and specify nonlinear solver\n",
    "  # print_level=0 turns off solver output\n",
    "  m = Model(solver=IpoptSolver(print_level=0))\n",
    "\n",
    "  # Add variables\n",
    "  @variable(m, β[1:p])\n",
    "  @variable(m, β0)\n",
    "\n",
    "  # Set nonlinear objective function with @NLobjective\n",
    "  @NLobjective(m, Max, -sum(\n",
    "    log(1 + exp(-Y[i] * (sum(X[i, j] * β[j] for j = 1:p) + β0)))\n",
    "    for i = 1:n))\n",
    "\n",
    "  # Solve the model and get the optimal solutions\n",
    "  solve(m)\n",
    "  return getvalue(β), getvalue(β0)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict_logit (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict_logit(X, β, β0)\n",
    "  [1.0 / (1.0 + e ^ -(dot(X[i, :], β) + β0)) for i = 1:size(X, 1)]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit http://projects.coin-or.org/Ipopt\n",
      "******************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "srand(1)\n",
    "\n",
    "# Noted for Logistic Regression, there are no hyper parameters to test, so I do not have a validation set. \n",
    "(train_X, train_y), (test_X, test_y) = splitobs(shuffleobs((X, Y)), at=0.50)\n",
    "\n",
    "\n",
    "train_X = Matrix(train_X)\n",
    "test_X = Matrix(test_X)\n",
    "\n",
    "train_Y = gamma1back0(train_y)\n",
    "test_Y = gamma1back0(test_y)\n",
    "\n",
    "β, β0 = logistic_regression(train_X, train_Y);\n",
    "pred = predict_logit(test_X, β, β0);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count() in module IterTools at deprecated.jl:56 overwritten in module Iterators at deprecated.jl:56.\n",
      "WARNING: Method definition count("
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19020, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number) in module IterTools at deprecated.jl:56 overwritten in module Iterators at deprecated.jl:56.\n",
      "WARNING: Method definition count(Number, Number) in module IterTools at deprecated.jl:56 overwritten in module Iterators at deprecated.jl:56.\n"
     ]
    }
   ],
   "source": [
    "size(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labelpred (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function labelpred(pred, threshold)\n",
    "    Int.(pred .> threshold)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best percent correct is 0.7914826498422713 which occurs when the threshold is 0.5816326530612245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: imported binding for label overwritten in module Main\n"
     ]
    }
   ],
   "source": [
    "best_percent = 0\n",
    "best_threshold = Inf\n",
    "for i in linspace(0,.95,50)\n",
    "    label = labelpred(pred, i)\n",
    "    percentcorrect = mean(label .== (test_Y))\n",
    "    if percentcorrect > best_percent\n",
    "        best_threshold = i\n",
    "        best_percent = percentcorrect\n",
    "    end\n",
    "end\n",
    "label = labelpred(pred,best_threshold)\n",
    "println(\"The best percent correct is \", best_percent, \" which occurs when the threshold is \", best_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9510-element Array{Int64,1}:\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " ⋮\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " test_Y = Array{Int64}(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8399763024025791"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using AUC\n",
    "auc(test_Y, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Int64,2}:\n",
       " 2202  1178\n",
       "  805  5325"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MLBase\n",
    "\n",
    "a = confusmat(2, test_Y + 1, label + 1) #create the confusion matrix here\n",
    "\n",
    "# true neg , false posi\n",
    "# false neg, true pos\n",
    "\n",
    "#put a cost  and add weights on points within the logistic regression \n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPrecompiling module ScikitLearn.\n",
      "\u001b[39mWARNING: Method definition "
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject <class 'sklearn.tree.tree.DecisionTreeClassifier'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "using ScikitLearn\n",
    "# Load in the DecisionTreeClassifier method from ScikitLearn\n",
    "@sk_import tree: DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lossfun (generic function with 1 method)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function lossfun(y_true, y_pred, loss_value) \n",
    "    #y_true is the actual values\n",
    "    #y_pred is the predictions\n",
    "    #loss_value matrix\n",
    "    a = confusmat(2, y_true + 1, y_pred + 1)\n",
    "    VALUE  = a.*loss_value\n",
    "    println(\"The loss function yields a score of \", VALUE[1,2], \"due to \", a[1,2], \" entries in the data which are false positives\")\n",
    "    println(\"The loss function yields a score of \", VALUE[2,1], \"due to \", a[2,1], \" entries in the data which are false negatives\")\n",
    "    return (sum(VALUE[2,1] + VALUE[1,2]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss function yields a score of [0, 1178]due to 1178 entries in the data which are false positives\n",
      "The loss function yields a score of [16100, 0]due to 805 entries in the data which are false negatives\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17278"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = test_Y \n",
    "y_pred = label\n",
    "loss_value = [[0,1],[20,0]]\n",
    "\n",
    "    #y_true is the actual values\n",
    "    #y_pred is the predictions\n",
    "    #loss_value matrix\n",
    "    a = confusmat(2, y_true + 1, y_pred + 1)\n",
    "    VALUE  = a.*loss_value\n",
    "    println(\"The loss function yields a score of \", VALUE[1,2], \"due to \", a[1,2], \" entries in the data which are false positives\")\n",
    "    println(\"The loss function yields a score of \", VALUE[2,1], \"due to \", a[2,1], \" entries in the data which are false negatives\")\n",
    "    return (sum(VALUE[2,1] + VALUE[1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pkg.build(\"GraphViz\")\n",
    "using GraphViz\n",
    "using PyCall\n",
    "@pyimport sklearn.tree as sktree\n",
    "\n",
    "function showtree(tree)\n",
    "    g = Graph(sktree.export_graphviz(tree, out_file=nothing, filled=true, rounded=true))\n",
    "    GraphViz.layout!(g; engine=\"dot\")\n",
    "    g\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9510-element Array{Float64,1}:\n",
       " 0.0\n",
       " 1.0\n",
       " 1.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 0.0\n",
       " 1.0\n",
       " 0.0\n",
       " 1.0\n",
       " ⋮  \n",
       " 1.0\n",
       " 0.0\n",
       " 0.0\n",
       " 1.0\n",
       " 0.0\n",
       " 1.0\n",
       " 0.0\n",
       " 1.0\n",
       " 0.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = myData1[1:end-1];\n",
    "Y = myData1[end];\n",
    "\n",
    "# Set minbucket with `min_samples_leaf` argument, and maxdepth with `max_depth`.\n",
    "srand(1)\n",
    "(train_X, train_y), (test_X, test_y) = splitobs(shuffleobs((X, Y)), at=0.50)\n",
    "(tr_X, tr_y), (vl_x, vl_y) = splitobs(shuffleobs((X, Y)), at=0.50)\n",
    "# cross validation \n",
    "tr_X = Matrix(tr_X)\n",
    "tr_y = gamma1back0(tr_y)\n",
    "vl_x = Matrix(vl_x)\n",
    "vl_y = gamma1back0(vl_y)\n",
    "train_X = Matrix(train_X)\n",
    "train_y = gamma1back0(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9510-element Array{Int64,1}:\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " ⋮\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_y = Array{Int64}(tr_y)\n",
    "vl_y = Array{Int64}(vl_y)\n",
    "train_y = Array{Int64}(train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject DecisionTreeClassifier(class_weight=None, criterion=5, max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter=3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "min_samples_leaf = 5\n",
    "max_depth = 3\n",
    "bestlosfunval = Inf\n",
    "bestminbucket = Inf\n",
    "bestdepth = Inf\n",
    "tree = DecisionTreeClassifier(min_samples_leaf, max_depth)  \n",
    "#         ScikitLearn.fit!(tree, tr_X, tr_y)\n",
    "#         for min_samples_leaf in [5, 10, 50, 100, 200]\n",
    "#             for max_depth in [1, 2, 3, 4, 5]\n",
    "#                 label = ScikitLearn.predict(tree, vl_x)\n",
    "#                 #showtree(tree)\n",
    "#                 losfunval = lossfun(Array{Int64}(vl_y), label,[[0,1],[20,0]])\n",
    "#                 if losfunval < bestlosfunval\n",
    "#                     bestlosfunval = losfunval\n",
    "#                     bestminbucket = min_samples_leaf\n",
    "#                     bestdepth = max_depth\n",
    "#                 end\n",
    "#             end\n",
    "#         end\n",
    "# @show bestlosfunval, bestminbucket, bestdepth\n",
    "\n",
    "# tuned_tree = DecisionTreeClassifier(bestminbucket, bestdepth)\n",
    "#     ScikitLearn.fit!(tuned_tree, train_X, train_y)\n",
    "#     label = ScikitLearn.predict(tuned_tree, test_X)\n",
    "#     losfunval = lossfun(test_y, label, [0,1;20,1])\n",
    "# println(\"For my best tree, my loss function value is\", losfunval)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
